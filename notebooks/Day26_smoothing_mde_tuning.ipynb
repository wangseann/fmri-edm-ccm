{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad8251b",
   "metadata": {},
   "source": [
    "# Day 26 – Smoothing ↔︎ MDE Tuning\n",
    "\n",
    "Explore how different smoothing controls impact category time-series and downstream ROI→category MDE performance for a single subject/story. The notebook reuses the Day19 category builder and Day22 MDE runner, plots smoothed categories, and captures MDE metrics while saving outputs under `figs/<subject>/<story>/day26_smoothing/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b197a0c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     25\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m/flash/PaoU/seann/pyEDM/src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     26\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m/flash/PaoU/seann/MDE-main/src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_yaml\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mday22_category_mde\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_mde_for_pair, sanitize_name\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecoding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_transcript_words\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/flash/PaoU/seann/fmri-edm-ccm/src/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Convenience exports for the fmri_edm_ccm package.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m baselines, ccm, edm, features, io_ds003020, plots, roi, run_demo, utils, day24_subject_concat, day25_bleed_correction\n\u001b[32m      5\u001b[39m __all__ = [\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbaselines\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mccm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mday25_bleed_correction\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/flash/PaoU/seann/fmri-edm-ccm/src/baselines.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ridge\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ensure_same_length, set_seed\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mridge_forecast\u001b[39m(X: np.ndarray, y: np.ndarray, alpha: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1.0\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m) -> np.ndarray:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/flash/PaoU/seann/fmri-edm-ccm/.venv/lib/python3.11/site-packages/sklearn/linear_model/__init__.py:35\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_huber\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuberRegressor\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_least_angle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     27\u001b[39m     Lars,\n\u001b[32m     28\u001b[39m     LarsCV,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     lars_path_gram,\n\u001b[32m     34\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logistic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression, LogisticRegressionCV\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_omp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     OrthogonalMatchingPursuit,\n\u001b[32m     38\u001b[39m     OrthogonalMatchingPursuitCV,\n\u001b[32m     39\u001b[39m     orthogonal_mp,\n\u001b[32m     40\u001b[39m     orthogonal_mp_gram,\n\u001b[32m     41\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_passive_aggressive\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PassiveAggressiveClassifier, PassiveAggressiveRegressor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/flash/PaoU/seann/fmri-edm-ccm/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_cv\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelBinarizer, LabelEncoder\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fit_liblinear\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     Bunch,\n\u001b[32m     26\u001b[39m     check_array,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     compute_class_weight,\n\u001b[32m     30\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, StrOptions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1138\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1078\u001b[39m, in \u001b[36m_find_spec\u001b[39m\u001b[34m(name, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1504\u001b[39m, in \u001b[36mfind_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1473\u001b[39m, in \u001b[36m_get_spec\u001b[39m\u001b[34m(cls, fullname, path, target)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1421\u001b[39m, in \u001b[36m_path_importer_cache\u001b[39m\u001b[34m(cls, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "\n",
    "import nbformat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception as exc:\n",
    "    plt = None\n",
    "    raise RuntimeError(f\"Matplotlib is required for Day26 plots: {exc}\")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = Path('/flash/PaoU/seann/fmri-edm-ccm')\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "sys.path.append('/flash/PaoU/seann/pyEDM/src')\n",
    "sys.path.append('/flash/PaoU/seann/MDE-main/src')\n",
    "\n",
    "\n",
    "\n",
    "from src.utils import load_yaml\n",
    "from src.day22_category_mde import run_mde_for_pair, sanitize_name\n",
    "from src.decoding import load_transcript_words\n",
    "from src.edm_ccm import English1000Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path('/flash/PaoU/seann/fmri-edm-ccm')\n",
    "CONFIG_PATH = PROJECT_ROOT / 'configs' / 'demo.yaml'\n",
    "\n",
    "cfg = load_yaml(CONFIG_PATH)\n",
    "paths: Dict[str, str] = cfg.get('paths', {}) or {}\n",
    "paths.setdefault('project_root', str(PROJECT_ROOT))\n",
    "for key in ('cache', 'figs', 'results'):\n",
    "    val = paths.get(key)\n",
    "    if val and not Path(val).is_absolute():\n",
    "        paths[key] = str((PROJECT_ROOT / val).resolve())\n",
    "\n",
    "SUBJECT = (cfg.get('subject') or 'UTS01').strip()\n",
    "STORY = (cfg.get('story') or 'wheretheressmoke').strip()\n",
    "TR = float(cfg.get('TR', 2.0))\n",
    "\n",
    "categories_cfg = cfg.get('categories', {}) or {}\n",
    "cluster_csv_rel = categories_cfg.get('cluster_csv_path', '')\n",
    "cluster_csv_path = str((PROJECT_ROOT / cluster_csv_rel).resolve()) if cluster_csv_rel else ''\n",
    "prototype_weight_power = float(categories_cfg.get('prototype_weight_power', 1.0))\n",
    "seconds_bin_width_default = float(categories_cfg.get('seconds_bin_width', 0.05))\n",
    "temporal_weighting_default = str(categories_cfg.get('temporal_weighting', 'proportional')).lower()\n",
    "\n",
    "TAU_GRID = cfg.get('tau_grid') or [1, 2]\n",
    "if isinstance(TAU_GRID, (int, float)):\n",
    "    TAU_GRID = [int(TAU_GRID)]\n",
    "E_CAP = int(cfg.get('E_mult', cfg.get('E_cap', 6)))\n",
    "\n",
    "FIGS_BASE = PROJECT_ROOT / 'figs' / SUBJECT / STORY / 'day26_smoothing'\n",
    "FIGS_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES_EVAL_BASE = PROJECT_ROOT / 'features_day26_eval'\n",
    "FEATURES_EVAL_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Subject/story: {SUBJECT} / {STORY}')\n",
    "print(f'Default tau grid: {TAU_GRID} | embedding cap: {E_CAP}')\n",
    "print(f'Cluster CSV: {cluster_csv_path or \"<none>\"}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00882caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse helper functions from Day19\n",
    "DAY19_NOTEBOOK = PROJECT_ROOT / 'notebooks' / 'Day19_smooth_categories.ipynb'\n",
    "day19_nb = nbformat.read(DAY19_NOTEBOOK, as_version=4)\n",
    "helper_code = day19_nb.cells[3].source\n",
    "generator_code = day19_nb.cells[4].source\n",
    "\n",
    "# Provide globals expected by the Day19 utilities\n",
    "EPS = 1e-12\n",
    "\n",
    "exec(helper_code, globals())\n",
    "exec(generator_code, globals())\n",
    "\n",
    "print('Loaded Day19 helper + generator functions.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build smoothing configuration grid with biologically motivated band\n",
    "PLAUDIBLE_BAND = (0.5, 2.0)  # seconds, roughly matching expected semantic/BOLD dynamics\n",
    "smooth_seconds_grid = np.round(np.arange(0.0, 1.25 + 1e-9, 0.25), 2)\n",
    "SMOOTHING_CONFIGS: List[Dict[str, object]] = []\n",
    "\n",
    "def _format_seconds_tag(seconds: float) -> str:\n",
    "    return f\"{seconds:.2f}\".replace('.', 'p')\n",
    "\n",
    "# Explicit \"no smoothing\" baseline at 0.0s\n",
    "SMOOTHING_CONFIGS.append({\n",
    "    'name': 'none_0p00',\n",
    "    'smoothing_seconds': 0.0,\n",
    "    'method': 'none',\n",
    "    'gaussian_sigma_seconds': None,\n",
    "    'pad_mode': 'edge',\n",
    "    'seconds_bin_width': seconds_bin_width_default,\n",
    "    'temporal_weighting': temporal_weighting_default,\n",
    "    'within_band': True,\n",
    "})\n",
    "\n",
    "# Add Gaussian + Moving Average for the remaining windows\n",
    "for seconds in smooth_seconds_grid:\n",
    "    seconds = float(seconds)\n",
    "    if seconds == 0.0:\n",
    "        continue\n",
    "    tag = _format_seconds_tag(seconds)\n",
    "\n",
    "    # Gaussian smoothing configuration\n",
    "    SMOOTHING_CONFIGS.append({\n",
    "        'name': f'gauss_{tag}',\n",
    "        'smoothing_seconds': seconds,\n",
    "        'method': 'gaussian',\n",
    "        'gaussian_sigma_seconds': seconds * 0.5,\n",
    "        'pad_mode': 'reflect',\n",
    "        'seconds_bin_width': seconds_bin_width_default,\n",
    "        'temporal_weighting': temporal_weighting_default,\n",
    "        'within_band': True,\n",
    "    })\n",
    "\n",
    "    # Moving-average smoothing configuration\n",
    "    SMOOTHING_CONFIGS.append({\n",
    "        'name': f'movavg_{tag}',\n",
    "        'smoothing_seconds': seconds,\n",
    "        'method': 'moving_average',\n",
    "        'gaussian_sigma_seconds': None,\n",
    "        'pad_mode': 'edge',\n",
    "        'seconds_bin_width': seconds_bin_width_default,\n",
    "        'temporal_weighting': temporal_weighting_default,\n",
    "        'within_band': True,\n",
    "    })\n",
    "\n",
    "print(f\"Evaluating {len(SMOOTHING_CONFIGS)} settings across windows {smooth_seconds_grid.tolist()} (none + gaussian + movavg).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686de174",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'cat_abstract'  # adjust if you want to optimize a different category\n",
    "\n",
    "results: List[Dict] = []\n",
    "\n",
    "for config in SMOOTHING_CONFIGS:\n",
    "    cfg_name = str(config['name']).strip() or 'config'\n",
    "    safe_name = sanitize_name(cfg_name)\n",
    "    smoothing_seconds = float(config['smoothing_seconds'])\n",
    "    smoothing_method = str(config['method'])\n",
    "    gaussian_sigma = config.get('gaussian_sigma_seconds')\n",
    "    pad_mode = config.get('pad_mode', 'edge')\n",
    "    seconds_bin_width = float(config.get('seconds_bin_width', seconds_bin_width_default))\n",
    "    temporal_weighting = str(config.get('temporal_weighting', temporal_weighting_default))\n",
    "    within_band = bool(config.get('within_band', False))\n",
    "\n",
    "    print(f\"=== Smoothing config: {cfg_name} | method={smoothing_method} | window={smoothing_seconds:.2f}s ===\")\n",
    "\n",
    "    features_root = FEATURES_EVAL_BASE / safe_name\n",
    "    globals()['features_root'] = features_root\n",
    "    features_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cluster_csv_use = cluster_csv_path\n",
    "    if cluster_csv_use and not Path(cluster_csv_use).is_absolute():\n",
    "        cluster_csv_use = str((PROJECT_ROOT / cluster_csv_use).resolve())\n",
    "    if cluster_csv_use and not Path(cluster_csv_use).exists():\n",
    "        warnings.warn(f'Cluster CSV not found at {cluster_csv_use}; proceeding without clusters.')\n",
    "        cluster_csv_use = ''\n",
    "\n",
    "    result = generate_category_time_series(\n",
    "        SUBJECT,\n",
    "        STORY,\n",
    "        cfg_base=cfg,\n",
    "        categories_cfg_base=categories_cfg,\n",
    "        cluster_csv_path=cluster_csv_use or '',\n",
    "        temporal_weighting=temporal_weighting,\n",
    "        prototype_weight_power=prototype_weight_power,\n",
    "        smoothing_seconds=smoothing_seconds,\n",
    "        smoothing_method=smoothing_method,\n",
    "        gaussian_sigma_seconds=gaussian_sigma,\n",
    "        smoothing_pad=pad_mode,\n",
    "        seconds_bin_width=seconds_bin_width,\n",
    "        save_outputs=False,\n",
    "    )\n",
    "\n",
    "    category_df = result['category_df_selected']\n",
    "    category_cols = result['category_columns']\n",
    "    if not category_cols:\n",
    "        raise RuntimeError('No category columns generated. Check configuration.')\n",
    "    if TARGET_COLUMN not in category_cols:\n",
    "        raise RuntimeError(f\"Target column {TARGET_COLUMN} not present in category dataframe.\")\n",
    "\n",
    "    target_series = category_df[TARGET_COLUMN].astype(float)\n",
    "    target_std = float(target_series.std(ddof=1))\n",
    "    target_range = float(target_series.max() - target_series.min())\n",
    "    target_diff = target_series.diff().dropna()\n",
    "    target_diff_mean = float(target_diff.abs().mean()) if not target_diff.empty else 0.0\n",
    "\n",
    "    top_cols = category_cols[:12]\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(14, 8), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    time_axis = category_df['start_sec']\n",
    "    for ax_idx, col in enumerate(top_cols):\n",
    "        ax = axes[ax_idx]\n",
    "        ax.plot(time_axis, category_df[col], linewidth=1.0)\n",
    "        ax.set_title(col)\n",
    "        ax.grid(alpha=0.3)\n",
    "    for ax_idx in range(len(top_cols), len(axes)):\n",
    "        axes[ax_idx].axis('off')\n",
    "    fig.suptitle(f'{SUBJECT} / {STORY} – {cfg_name} smoothing')\n",
    "    fig.tight_layout(rect=(0, 0, 1, 0.96))\n",
    "\n",
    "    plot_dir = FIGS_BASE / safe_name\n",
    "    plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = plot_dir / 'category_timeseries_overview.png'\n",
    "    fig.savefig(plot_path, dpi=180)\n",
    "    plt.close(fig)\n",
    "    print(f'Saved category plot to {plot_path}')\n",
    "\n",
    "    eval_root = FEATURES_EVAL_BASE / safe_name\n",
    "    category_dir = eval_root / 'subjects' / SUBJECT / STORY\n",
    "    category_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cat_csv = category_dir / 'category_timeseries.csv'\n",
    "    category_df.to_csv(cat_csv, index=False)\n",
    "\n",
    "    figs_root_config = FIGS_BASE / safe_name\n",
    "\n",
    "    summary = run_mde_for_pair(\n",
    "        SUBJECT,\n",
    "        STORY,\n",
    "        target_column=TARGET_COLUMN,\n",
    "        features_root=eval_root,\n",
    "        figs_root=figs_root_config,\n",
    "        paths_cfg=paths,\n",
    "        n_parcels=int(cfg.get('n_parcels', 400)),\n",
    "        tau_grid=TAU_GRID,\n",
    "        E_cap=E_CAP,\n",
    "        lib_sizes=cfg.get('lib_sizes', [80, 120, 160]),\n",
    "        delta_default=int((cfg.get('delta') or [1])[0]),\n",
    "        theiler_min=int(cfg.get('theiler_min', 3)),\n",
    "        train_frac=0.5,\n",
    "        val_frac=0.25,\n",
    "        top_n_plot=6,\n",
    "        save_input_frame=True,\n",
    "        save_scatter=True,\n",
    "        plt_module=plt,\n",
    "    )\n",
    "\n",
    "    selection_path = Path(summary['selection_csv'])\n",
    "    mde_df = pd.read_csv(selection_path)\n",
    "    rho_col = next((c for c in mde_df.columns if c.lower().startswith('rho')), None)\n",
    "    best_rho = float(mde_df[rho_col].iloc[0]) if rho_col and not mde_df.empty else float('nan')\n",
    "    rho_top5 = mde_df[rho_col].head(5) if rho_col else pd.Series(dtype=float)\n",
    "    rho_mean_top5 = float(rho_top5.mean()) if not rho_top5.empty else float('nan')\n",
    "    rho_median_top5 = float(rho_top5.median()) if not rho_top5.empty else float('nan')\n",
    "    rho_std_top5 = float(rho_top5.std(ddof=1)) if len(rho_top5) >= 2 else float('nan')\n",
    "    positive_rho_top5 = int((rho_top5 > 0).sum()) if not rho_top5.empty else 0\n",
    "\n",
    "    best_var_col = 'variables' if 'variables' in mde_df.columns else 'variable'\n",
    "    best_variable = str(mde_df[best_var_col].iloc[0]) if not mde_df.empty else ''\n",
    "    top5_variables = mde_df[best_var_col].head(5).astype(str) if best_var_col in mde_df.columns else pd.Series(dtype=str)\n",
    "    unique_top5 = int(top5_variables.nunique()) if not top5_variables.empty else 0\n",
    "\n",
    "    results.append({\n",
    "        'config': cfg_name,\n",
    "        'safe_name': safe_name,\n",
    "        'method': smoothing_method,\n",
    "        'smoothing_seconds': smoothing_seconds,\n",
    "        'within_plausible_band': within_band,\n",
    "        'gaussian_sigma_seconds': gaussian_sigma,\n",
    "        'pad_mode': pad_mode,\n",
    "        'seconds_bin_width': seconds_bin_width,\n",
    "        'temporal_weighting': temporal_weighting,\n",
    "        'top_variable': best_variable,\n",
    "        'top_rho': best_rho,\n",
    "        'rho_mean_top5': rho_mean_top5,\n",
    "        'rho_median_top5': rho_median_top5,\n",
    "        'rho_std_top5': rho_std_top5,\n",
    "        'positive_rho_top5': positive_rho_top5,\n",
    "        'unique_top5_variables': unique_top5,\n",
    "        'target_std': target_std,\n",
    "        'target_range': target_range,\n",
    "        'target_diff_abs_mean': target_diff_mean,\n",
    "        'selection_csv': str(selection_path),\n",
    "        'plot_dir': str(plot_dir),\n",
    "        'mde_dir': str(figs_root_config / 'day22_category_mde'),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=['method', 'smoothing_seconds']).reset_index(drop=True)\n",
    "display(results_df)\n",
    "summary_path = FIGS_BASE / 'day26_mde_smoothing_summary.csv'\n",
    "results_df.to_csv(summary_path, index=False)\n",
    "print(f'Summary saved to {summary_path}')\n",
    "\n",
    "# Build method × smoothing matrices for multiple metrics\n",
    "if not results_df.empty:\n",
    "    metrics_to_pivot = {\n",
    "        'top_rho': 'Top rho',\n",
    "        'rho_mean_top5': 'Mean rho (top5)',\n",
    "        'rho_median_top5': 'Median rho (top5)',\n",
    "        'target_std': 'Target std',\n",
    "        'target_range': 'Target range',\n",
    "        'target_diff_abs_mean': 'Mean |Δtarget|',\n",
    "    }\n",
    "    pivot_dir = FIGS_BASE / 'matrices'\n",
    "    pivot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for metric_key, metric_label in metrics_to_pivot.items():\n",
    "        matrix = results_df.pivot(index='smoothing_seconds', columns='method', values=metric_key)\n",
    "        display(matrix)\n",
    "        matrix_path = pivot_dir / f'day26_{metric_key}_matrix.csv'\n",
    "        matrix.to_csv(matrix_path)\n",
    "        print(f\"{metric_label} matrix saved to {matrix_path}\")\n",
    "else:\n",
    "    print('No results captured; skipping matrix export.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-edm-ccm (.venv)",
   "language": "python",
   "name": "fmri-edm-ccm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
