{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739baac0",
   "metadata": {},
   "source": [
    "# Day 6 — ROI Mask QA (stepwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac08c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "try:\n",
    "    import cortex\n",
    "    HAVE_PYCORTEX = True\n",
    "except ImportError:\n",
    "    HAVE_PYCORTEX = False\n",
    "    print('pycortex not available — install with `pip install pycortex` if you need surface transforms.')\n",
    "\n",
    "try:\n",
    "    import nibabel as nib\n",
    "except ImportError as exc:\n",
    "    raise RuntimeError('nibabel is required to read FreeSurfer annotation files. Install with `pip install nibabel`.') from exc\n",
    "\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "DATA_ROOT = Path('/bucket/PaoU/seann/openneuro/ds003020')\n",
    "PREPROC_ROOT = DATA_ROOT / 'derivative' / 'preprocessed_data'\n",
    "PYCORTEX_DB = DATA_ROOT / 'derivative' / 'pycortex-db'\n",
    "FREESURFER_SUBJECTS = DATA_ROOT / 'derivative' / 'freesurfer_subjdir'\n",
    "TRANSFORM_PATH = DATA_ROOT / 'derivative' / 'subject_xfms.json'\n",
    "\n",
    "SUBJECT_ID = 'sub-UTS01'\n",
    "SUBJECT_FS = SUBJECT_ID.replace('sub-', '')\n",
    "STORY_IDS = ['adventuresinsayingyes', 'adollshouse']\n",
    "TR = 2.0\n",
    "\n",
    "for path in [DATA_ROOT, PREPROC_ROOT, PYCORTEX_DB, FREESURFER_SUBJECTS, TRANSFORM_PATH]:\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(f'Required resource missing: {path}')\n",
    "\n",
    "with TRANSFORM_PATH.open() as fh:\n",
    "    transform_map = json.load(fh)\n",
    "TRANSFORM_ID = transform_map.get(SUBJECT_FS)\n",
    "if TRANSFORM_ID is None:\n",
    "    raise KeyError(f'No transform entry for {SUBJECT_FS} in {TRANSFORM_PATH}')\n",
    "\n",
    "print(f'Subject {SUBJECT_ID}: transform {TRANSFORM_ID}')\n",
    "print(f'pycortex available: {HAVE_PYCORTEX}')\n",
    "print(f'Stories to process: {STORY_IDS}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fs_annotations(subject_fs: str, atlas: str = 'aparc') -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"Load FreeSurfer annotation labels for left/right hemispheres.\"\"\"\n",
    "    annotations: Dict[str, Dict[str, np.ndarray]] = {}\n",
    "    for hemi in ('lh', 'rh'):\n",
    "        annot_path = FREESURFER_SUBJECTS / subject_fs / 'label' / f'{hemi}.{atlas}.annot'\n",
    "        if not annot_path.exists():\n",
    "            raise FileNotFoundError(f'Missing annotation file: {annot_path}')\n",
    "        labels, ctab, names = nib.freesurfer.read_annot(str(annot_path))\n",
    "        decoded = [name.decode('utf-8') if isinstance(name, bytes) else str(name) for name in names]\n",
    "        annotations[hemi] = {\n",
    "            'labels': labels,\n",
    "            'ctab': ctab,\n",
    "            'names': decoded,\n",
    "        }\n",
    "    return annotations\n",
    "\n",
    "fs_ann = load_fs_annotations(SUBJECT_FS)\n",
    "print(f\"Loaded FreeSurfer annotations for {SUBJECT_FS}:\")\n",
    "for hemi in ('lh', 'rh'):\n",
    "    labels = fs_ann[hemi]['labels']\n",
    "    names = fs_ann[hemi]['names']\n",
    "    print(f\"  {hemi}: {len(names)} labels, {labels.size} vertices\")\n",
    "    print(f\"    first labels: {', '.join(names[:10])}\")\n",
    "\n",
    "LANGUAGE_ROIS = {\n",
    "    'lh': ['parsopercularis', 'parstriangularis', 'superiortemporal', 'middletemporal', 'temporalpole', 'bankssts', 'inferiorparietal', 'supramarginal'],\n",
    "    'rh': ['parsopercularis', 'parstriangularis', 'superiortemporal', 'middletemporal', 'temporalpole', 'bankssts', 'inferiorparietal', 'supramarginal'],\n",
    "}\n",
    "\n",
    "ROI_FILTER = LANGUAGE_ROIS\n",
    "print('ROI_FILTER set to language subset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_label(text: str) -> str:\n",
    "    return ''.join(ch for ch in text.lower() if ch.isalnum())\n",
    "\n",
    "\n",
    "def build_fs_roi_masks(\n",
    "    annotations: Dict[str, Dict[str, np.ndarray]],\n",
    "    roi_filter: Optional[Dict[str, list]] = None,\n",
    ") -> Dict[str, Dict[str, np.ndarray]]:\n",
    "    \"\"\"Create hemisphere-specific boolean masks from FreeSurfer annotations.\"\"\"\n",
    "    masks: Dict[str, Dict[str, np.ndarray]] = {}\n",
    "    for hemi in ('lh', 'rh'):\n",
    "        labels = annotations[hemi]['labels']\n",
    "        names = annotations[hemi]['names']\n",
    "        name_to_index = {_normalize_label(name): (name, idx) for idx, name in enumerate(names)}\n",
    "        requested = roi_filter.get(hemi) if roi_filter else names\n",
    "        hemi_masks: Dict[str, np.ndarray] = {}\n",
    "        for roi in requested:\n",
    "            norm = _normalize_label(roi)\n",
    "            candidates = [norm]\n",
    "            if roi in ROI_NAME_OVERRIDES:\n",
    "                candidates.extend(_normalize_label(alias) for alias in ROI_NAME_OVERRIDES[roi])\n",
    "            match = None\n",
    "            for cand in candidates:\n",
    "                if cand in name_to_index:\n",
    "                    match = name_to_index[cand]\n",
    "                    break\n",
    "            if match is None:\n",
    "                available = ', '.join(names[:10])\n",
    "                raise KeyError(f'ROI {hemi}-{roi} not found in annotations. Sample names: {available}')\n",
    "            match_name, match_idx = match\n",
    "            mask = labels == match_idx\n",
    "            hemi_masks[f'{hemi}-{roi}'] = mask\n",
    "        masks[hemi] = hemi_masks\n",
    "    return masks\n",
    "\n",
    "ROI_NAME_OVERRIDES = {\n",
    "    'parsopercularis': ['G_front_inf-Opercular'],\n",
    "    'parstriangularis': ['G_front_inf-Triangul'],\n",
    "    'superiortemporal': ['G_temporal_sup'],\n",
    "    'middletemporal': ['G_temporal_middle'],\n",
    "    'temporalpole': ['Pole_temporal'],\n",
    "    'bankssts': ['S_temporal_sup-Lateral'],\n",
    "    'inferiorparietal': ['G_pariet_inf-Angular'],\n",
    "    'supramarginal': ['G_pariet_inf-Supramar'],\n",
    "}\n",
    "\n",
    "fs_masks_native = build_fs_roi_masks(fs_ann, ROI_FILTER)\n",
    "for hemi, hemi_masks in fs_masks_native.items():\n",
    "    print(f'{hemi}: {len(hemi_masks)} masks')\n",
    "    for roi, mask in hemi_masks.items():\n",
    "        print(f'  {roi}: {int(mask.sum())} vertices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ecdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not HAVE_PYCORTEX:\n",
    "    raise RuntimeError('pycortex is required to project FreeSurfer ROI masks to the functional surface.')\n",
    "\n",
    "cortex.config.default_db = str(PYCORTEX_DB)\n",
    "cortex.config.default_filestore = str(PYCORTEX_DB)\n",
    "cortex.config.default_subject = SUBJECT_FS\n",
    "cortex.database.default_filestore = str(PYCORTEX_DB)\n",
    "cortex.database.db = cortex.database.Database(str(PYCORTEX_DB))\n",
    "cortex.db = cortex.database.db\n",
    "\n",
    "import cortex.dataset\n",
    "cortex.dataset.db = cortex.database.db\n",
    "import cortex.dataset.braindata as _braindata\n",
    "_braindata.db = cortex.database.db\n",
    "import cortex.dataset.views as _views\n",
    "_views.db = cortex.database.db\n",
    "\n",
    "subjects = cortex.db.subjects\n",
    "print(f\"pycortex subjects detected: {list(subjects.keys())[:5]} ... total={len(subjects)}\")\n",
    "\n",
    "coord = cortex.db.get_xfm(SUBJECT_FS, TRANSFORM_ID, xfmtype='coord')\n",
    "magnet = cortex.db.get_xfm(SUBJECT_FS, TRANSFORM_ID, xfmtype='magnet')\n",
    "print('coord type:', type(coord), 'magnet type:', type(magnet))\n",
    "print('coord repr:', coord)\n",
    "print('magnet repr:', magnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b131b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import shutil\n",
    "import numpy as np\n",
    "from cortex import freesurfer\n",
    "\n",
    "def _parse_surf_numpy2(filename: str):\n",
    "    \"\"\"Read FreeSurfer surface files using NumPy 2 compatible buffer APIs.\"\"\"\n",
    "    with open(filename, 'rb') as fp:\n",
    "        fp.seek(3)\n",
    "        comment = fp.readline()\n",
    "        fp.readline()\n",
    "        verts, faces = struct.unpack('>2I', fp.read(8))\n",
    "        pts_raw = fp.read(4 * 3 * verts)\n",
    "        polys_raw = fp.read(4 * 3 * faces)\n",
    "    print(comment)\n",
    "    pts = np.frombuffer(pts_raw, dtype=np.dtype('>f4'), count=verts * 3)\n",
    "    polys = np.frombuffer(polys_raw, dtype=np.dtype('>i4'), count=faces * 3)\n",
    "    if pts.size != verts * 3 or polys.size != faces * 3:\n",
    "        raise ValueError(\n",
    "            f\"parse_surf: expected {verts * 3} floats and {faces * 3} ints, \"\n",
    "            f\"got {pts.size} floats and {polys.size} ints from {filename}\"\n",
    "        )\n",
    "    pts = pts.astype(np.float32, copy=False).reshape(-1, 3)\n",
    "    polys = polys.astype(np.int32, copy=False).reshape(-1, 3)\n",
    "    return pts, polys\n",
    "\n",
    "def _parse_curv_numpy2(filename: str):\n",
    "    \"\"\"Parse FreeSurfer curvature files using NumPy 2 compatible APIs.\"\"\"\n",
    "    with open(filename, 'rb') as fp:\n",
    "        fp.seek(15)\n",
    "        data = fp.read()\n",
    "    arr = np.frombuffer(data, dtype=np.dtype('>f4'))\n",
    "    return arr.astype(np.float32, copy=False)\n",
    "\n",
    "def _parse_patch_numpy2(filename: str):\n",
    "    \"\"\"Parse FreeSurfer patch files using NumPy 2 compatible APIs.\"\"\"\n",
    "    with open(filename, 'rb') as fp:\n",
    "        header = struct.unpack('>i', fp.read(4))[0]\n",
    "        nverts = struct.unpack('>i', fp.read(4))[0]\n",
    "        raw = fp.read()\n",
    "    dtype = np.dtype([('vert', '>i4'), ('x', '>f4'), ('y', '>f4'), ('z', '>f4')])\n",
    "    data = np.frombuffer(raw, dtype=dtype)\n",
    "    if len(data) != nverts:\n",
    "        raise ValueError(\n",
    "            f\"parse_patch: expected {nverts} vertices, got {len(data)} from {filename}\"\n",
    "        )\n",
    "    return data\n",
    "\n",
    "_original_mri_surf2surf = freesurfer.mri_surf2surf\n",
    "\n",
    "def _mri_surf2surf_with_fallback(data, source_subj, target_subj, hemi, subjects_dir=None):\n",
    "    \"\"\"Fallback to identity transform when mri_surf2surf binary is unavailable.\"\"\"\n",
    "    if shutil.which('mri_surf2surf') is None:\n",
    "        if source_subj != target_subj:\n",
    "            raise FileNotFoundError(\n",
    "                \"mri_surf2surf binary not found in PATH; load FreeSurfer or install the command \"\n",
    "                \"to map between different subjects.\"\n",
    "            )\n",
    "        return np.asarray(data)\n",
    "    return _original_mri_surf2surf(data, source_subj, target_subj, hemi, subjects_dir=subjects_dir)\n",
    "\n",
    "freesurfer.parse_surf = _parse_surf_numpy2\n",
    "freesurfer.parse_curv = _parse_curv_numpy2\n",
    "freesurfer.parse_patch = _parse_patch_numpy2\n",
    "freesurfer.mri_surf2surf = _mri_surf2surf_with_fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd284fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex import freesurfer, utils\n",
    "\n",
    "SURFACE_TYPE = 'fiducial'\n",
    "print(f'Using FreeSurfer surface: {SURFACE_TYPE}')\n",
    "\n",
    "mapper_lh = freesurfer.get_mri_surf2surf_matrix(\n",
    "    SUBJECT_FS, 'lh', SURFACE_TYPE,\n",
    "    target_subj=SUBJECT_FS,\n",
    "    subjects_dir=str(FREESURFER_SUBJECTS)\n",
    ")\n",
    "mapper_rh = freesurfer.get_mri_surf2surf_matrix(\n",
    "    SUBJECT_FS, 'rh', SURFACE_TYPE,\n",
    "    target_subj=SUBJECT_FS,\n",
    "    subjects_dir=str(FREESURFER_SUBJECTS)\n",
    ")\n",
    "\n",
    "print('mapper_lh shape:', mapper_lh.shape)\n",
    "print('mapper_rh shape:', mapper_rh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b496b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_masks = {}\n",
    "mapper = utils.get_mapper(SUBJECT_FS, TRANSFORM_ID, recache=False)\n",
    "mask_flat = mapper.mask.reshape(-1).astype(bool)\n",
    "\n",
    "n_lh = mapper_lh.shape[0]\n",
    "n_rh = mapper_rh.shape[0]\n",
    "\n",
    "for roi_key, mask in fs_masks_native['lh'].items():\n",
    "    lh_projected = mapper_lh.dot(mask.astype(float))\n",
    "    flat = np.concatenate([lh_projected, np.zeros(n_rh)])\n",
    "    roi_mask = (flat > 0)\n",
    "    resampled_masks[roi_key] = roi_mask & mask_flat\n",
    "    print(f\"{roi_key}: {resampled_masks[roi_key].sum()} vertices\")\n",
    "\n",
    "for roi_key, mask in fs_masks_native['rh'].items():\n",
    "    rh_projected = mapper_rh.dot(mask.astype(float))\n",
    "    flat = np.concatenate([np.zeros(n_lh), rh_projected])\n",
    "    roi_mask = (flat > 0)\n",
    "    resampled_masks[roi_key] = roi_mask & mask_flat\n",
    "    print(f\"{roi_key}: {resampled_masks[roi_key].sum()} vertices\")\n",
    "\n",
    "print('Total ROI masks:', len(resampled_masks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fbed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_story_bold(subject_fs: str, story_id: str):\n",
    "    h5_path = PREPROC_ROOT / subject_fs / f'{story_id}.hf5'\n",
    "    if not h5_path.exists():\n",
    "        raise FileNotFoundError(f'Missing preprocessed file: {h5_path}')\n",
    "    with h5py.File(h5_path, 'r') as hf:\n",
    "        data = hf['data'][:]\n",
    "    return data\n",
    "\n",
    "story_id = STORY_IDS[0]\n",
    "bold = load_story_bold(SUBJECT_FS, story_id)\n",
    "print('BOLD shape:', bold.shape)\n",
    "\n",
    "roi_ts = {}\n",
    "for roi_key, mask in resampled_masks.items():\n",
    "    roi_ts[roi_key] = bold[:, mask].mean(axis=1)\n",
    "    print(f\"{roi_key}: timeseries shape {roi_ts[roi_key].shape}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
