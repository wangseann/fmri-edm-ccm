"""
Interactive QA-Emb alignment explorer for post-hoc analysis.

Usage:
    from notebooks.tools.qaemb_alignment_explorer import launch_alignment_explorer
    launch_alignment_explorer(project_root="/flash/PaoU/seann/fmri-edm-ccm", subject="UTS01", story="wheretheressmoke")

The explorer expects the QAEmb outputs generated by scripts/dayxx_qaemb_timeseries.py:
- Token embeddings: featurestest/qaemb/tokens/<SUBJECT>/<STORY>_qaemb_tokens.npy
- Question list:   featurestest/qaemb/tokens/<SUBJECT>/<STORY>_qaemb_questions.json
- Canonical time series: featurestest/qaemb/stories/<STORY>/qaemb_timeseries_seconds.csv
- TR time series: featurestest/qaemb/subjects/<SUBJECT>/<STORY>/qaemb_timeseries.csv
"""

import json
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

try:
    import ipywidgets as widgets
    from IPython.display import display
except Exception:  # pragma: no cover - optional dependency for notebooks
    widgets = None
    display = None

DEFAULT_PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(DEFAULT_PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(DEFAULT_PROJECT_ROOT))

from src.utils import load_yaml
from src.decoding import load_transcript_words


def abbreviate_question(q: str, max_words: int = 3) -> str:
    q = str(q).strip()
    if q.endswith("?"):
        q = q[:-1]
    words = q.split()
    return " ".join(words[:max_words])


def _resolve_path(path: Optional[str], project_root: Path) -> Optional[Path]:
    if path is None:
        return None
    candidate = Path(path)
    if not candidate.is_absolute():
        candidate = project_root / candidate
    return candidate


def load_alignment_data(
    *,
    project_root: Optional[str] = None,
    config_path: str = "configs/demo.yaml",
    subject: Optional[str] = None,
    story: Optional[str] = None,
    token_df: Optional[pd.DataFrame] = None,
    token_csv: Optional[str] = None,
    qa_tokens_path: Optional[str] = None,
    canonical_csv_path: Optional[str] = None,
    tr_csv_path: Optional[str] = None,
    questions_path: Optional[str] = None,
) -> Dict[str, Any]:
    project_root_path = Path(project_root or DEFAULT_PROJECT_ROOT).expanduser().resolve()
    cfg_path = Path(config_path)
    if not cfg_path.is_absolute():
        cfg_path = project_root_path / cfg_path
    cfg = load_yaml(cfg_path)
    paths = cfg.get("paths", {}) or {}
    subject = subject or cfg.get("subject")
    story = story or cfg.get("story")
    if not subject or not story:
        raise ValueError("Subject and story must be provided via arguments or config.")

    features_root = Path(paths.get("featurestest", "featurestest"))
    if not features_root.is_absolute():
        features_root = project_root_path / features_root
    features_root = features_root / "qaemb"

    qa_tokens_path = _resolve_path(qa_tokens_path, project_root_path)
    if qa_tokens_path is None:
        qa_tokens_path = features_root / "tokens" / subject / f"{story}_qaemb_tokens.npy"
    qa_tokens_path = qa_tokens_path.expanduser()
    if not qa_tokens_path.exists():
        raise FileNotFoundError(f"QA token embedding file not found: {qa_tokens_path}")
    qa_matrix = np.load(qa_tokens_path)

    if questions_path is None:
        questions_path = features_root / "tokens" / subject / f"{story}_qaemb_questions.json"
        if not questions_path.exists():
            qa_cfg = cfg.get("qa_emb", {}) or {}
            q_rel = qa_cfg.get("questions_path", "configs/qaemb_questions.json")
            questions_path = _resolve_path(q_rel, project_root_path)
    else:
        questions_path = _resolve_path(questions_path, project_root_path)
    if questions_path is None or not Path(questions_path).exists():
        raise FileNotFoundError("QA questions JSON not found; provide questions_path or ensure the token export wrote it.")
    QA_QUESTIONS: List[str] = json.loads(Path(questions_path).read_text())
    qa_abbrevs = [abbreviate_question(q) for q in QA_QUESTIONS]

    if token_df is None:
        if token_csv is not None:
            token_path = _resolve_path(token_csv, project_root_path)
            token_df = pd.read_csv(token_path)
        else:
            events = load_transcript_words(paths, subject, story)
            token_df = pd.DataFrame(events, columns=["word", "start", "end"])
        token_df["word"] = token_df["word"].astype(str).str.strip()
        token_df["midpoint"] = 0.5 * (token_df["start"] + token_df["end"])
        token_df["token_index"] = np.arange(len(token_df))
    token_df = token_df.copy()

    canonical_csv_path = _resolve_path(canonical_csv_path, project_root_path)
    if canonical_csv_path is None:
        canonical_csv_path = features_root / "stories" / story / "qaemb_timeseries_seconds.csv"
    canonical_csv_path = canonical_csv_path.expanduser()
    if not canonical_csv_path.exists():
        raise FileNotFoundError(f"Canonical QA time series not found: {canonical_csv_path}")
    canonical_df = pd.read_csv(canonical_csv_path)

    tr_csv_path = _resolve_path(tr_csv_path, project_root_path)
    if tr_csv_path is None:
        tr_csv_path = features_root / "subjects" / subject / story / "qaemb_timeseries.csv"
    tr_csv_path = tr_csv_path.expanduser()
    if not tr_csv_path.exists():
        raise FileNotFoundError(f"TR QA time series not found: {tr_csv_path}")
    tr_df = pd.read_csv(tr_csv_path)

    qa_columns = [col for col in canonical_df.columns if col.startswith("qa_q")]
    canonical_time = 0.5 * (canonical_df["start_sec"].to_numpy() + canonical_df["end_sec"].to_numpy())
    tr_time = tr_df["start_sec"].to_numpy()

    return {
        "project_root": project_root_path,
        "subject": subject,
        "story": story,
        "token_df": token_df,
        "qa_matrix": qa_matrix,
        "qa_questions": QA_QUESTIONS,
        "qa_abbrevs": qa_abbrevs,
        "qa_columns": qa_columns,
        "canonical_df": canonical_df,
        "tr_df": tr_df,
        "canonical_time": canonical_time,
        "tr_time": tr_time,
    }


def launch_alignment_explorer(
    *,
    project_root: Optional[str] = None,
    config_path: str = "configs/demo.yaml",
    subject: Optional[str] = None,
    story: Optional[str] = None,
    token_df: Optional[pd.DataFrame] = None,
    token_csv: Optional[str] = None,
    qa_tokens_path: Optional[str] = None,
    canonical_csv_path: Optional[str] = None,
    tr_csv_path: Optional[str] = None,
    questions_path: Optional[str] = None,
) -> None:
    if widgets is None or display is None:
        raise ImportError("ipywidgets and IPython.display are required for the alignment explorer.")

    data = load_alignment_data(
        project_root=project_root,
        config_path=config_path,
        subject=subject,
        story=story,
        token_df=token_df,
        token_csv=token_csv,
        qa_tokens_path=qa_tokens_path,
        canonical_csv_path=canonical_csv_path,
        tr_csv_path=tr_csv_path,
        questions_path=questions_path,
    )

    subject = data["subject"]
    story = data["story"]
    token_df = data["token_df"]
    qa_matrix = data["qa_matrix"]
    qa_columns = data["qa_columns"]
    canonical_df = data["canonical_df"]
    tr_df = data["tr_df"]
    canonical_time = data["canonical_time"]
    tr_time = data["tr_time"]
    qa_questions = data["qa_questions"]
    qa_abbrevs = data["qa_abbrevs"]

    TOKEN_BASE_DF = token_df[["token_index", "word", "start", "end", "midpoint"]].copy()
    TOKEN_BASE_DF["duration"] = TOKEN_BASE_DF["end"] - TOKEN_BASE_DF["start"]
    QA_SCORE_CACHE = {col: qa_matrix[:, idx].astype(float) for idx, col in enumerate(qa_columns)}
    QA_SCORE_ABS_MAX = float(np.nanmax(np.abs(qa_matrix))) if qa_matrix.size else 0.0
    qa_name_lookup = {col: qa_questions[idx] if idx < len(qa_questions) else col for idx, col in enumerate(qa_columns)}

    MAX_TOKENS_DISPLAY = 60
    FOCUS_WINDOW_SECONDS = 20.0

    def _interpolate_series(series_values: pd.Series, times: np.ndarray, query: np.ndarray) -> np.ndarray:
        values = np.asarray(series_values, dtype=float)
        times = np.asarray(times, dtype=float)
        query = np.asarray(query, dtype=float)
        if values.size == 0 or times.size == 0:
            return np.full(query.shape, np.nan, dtype=float)
        finite = np.isfinite(values)
        if finite.sum() < 2:
            return np.full(query.shape, np.nan, dtype=float)
        interp = np.interp(query, times[finite], values[finite])
        interp[(query < times[finite][0]) | (query > times[finite][-1])] = np.nan
        return interp

    def _prepare_subset(col: str, t0: float, t1: float) -> pd.DataFrame:
        mask = (TOKEN_BASE_DF["midpoint"] >= t0) & (TOKEN_BASE_DF["midpoint"] <= t1)
        subset = TOKEN_BASE_DF.loc[mask].copy()
        scores = QA_SCORE_CACHE.get(col)
        if scores is None:
            raise RuntimeError(f"No cached scores for {col}")
        subset["score"] = scores[mask.to_numpy()]
        subset["abs_score"] = subset["score"].abs()
        subset.sort_values("start", inplace=True)
        subset["canonical_value"] = _interpolate_series(canonical_df[col], canonical_time, subset["midpoint"].to_numpy())
        subset["tr_value"] = _interpolate_series(tr_df[col], tr_time, subset["midpoint"].to_numpy())
        return subset

    def _plot_alignment(col: str, subset: pd.DataFrame, highlight: pd.DataFrame, *, t0: float, t1: float, question_label: str):
        import matplotlib.lines as mlines

        highlight_ranked = highlight.sort_values("score", ascending=False)
        if len(highlight_ranked) > MAX_TOKENS_DISPLAY:
            plot_highlight = highlight_ranked.head(MAX_TOKENS_DISPLAY).sort_values("midpoint")
        else:
            plot_highlight = highlight_ranked.sort_values("midpoint")

        series_canon = canonical_df[col].to_numpy(dtype=float)
        series_tr = tr_df[col].to_numpy(dtype=float)
        max_abs = float(np.nanmax(np.abs(subset["score"].to_numpy()))) if subset["score"].notna().any() else 1.0
        max_abs = max(max_abs, 1.0)

        fig = plt.figure(figsize=(14, 5))
        gs = fig.add_gridspec(2, 1, height_ratios=[3, 1], hspace=0.12)
        ax = fig.add_subplot(gs[0])
        ax_tokens = fig.add_subplot(gs[1], sharex=ax)

        canon_mask = (canonical_time >= t0) & (canonical_time <= t1)
        tr_mask = (tr_time >= t0) & (tr_time <= t1)
        ax.plot(canonical_time[canon_mask], series_canon[canon_mask], color="tab:blue", label="Canonical (smoothed)")
        ax.plot(tr_time[tr_mask], series_tr[tr_mask], color="tab:orange", label="TR (smoothed)")

        token_handle = None
        if not plot_highlight.empty:
            scale = float(np.nanmax(plot_highlight["abs_score"].to_numpy())) if plot_highlight["abs_score"].notna().any() else 0.0
            scale = scale if scale > 0 else 1.0
            colors = np.where(plot_highlight["score"] >= 0, "tab:green", "tab:red")
            sizes = 60 + 200 * (plot_highlight["abs_score"] / scale)
            ax.scatter(plot_highlight["midpoint"], plot_highlight["canonical_value"], s=sizes, c=colors, alpha=0.9, edgecolor="white", linewidth=0.4)
            token_handle = mlines.Line2D([], [], marker="o", linestyle="None", color="tab:green", markerfacecolor="tab:green", markeredgecolor="white", label="Transcript tokens")

            ax_tokens.axhline(0.0, color="0.6", linewidth=1.0)
            ax_tokens.vlines(plot_highlight["midpoint"], 0.0, plot_highlight["score"], colors=colors, linewidth=2.0, alpha=0.8)
            for row in plot_highlight.itertuples():
                y = row.score
                offset = 0.04 * max_abs
                text_y = y + offset if y >= 0 else y - offset
                va = "bottom" if y >= 0 else "top"
                ax_tokens.text(row.midpoint, text_y, row.word, rotation=90, ha="center", va=va, fontsize=8)
            ax_tokens.set_ylim(-max_abs * 1.3, max_abs * 1.3)
        else:
            ax_tokens.axhline(0.0, color="0.6", linewidth=1.0)
            ax_tokens.text(0.5, 0.5, "No tokens matched the current filters", transform=ax_tokens.transAxes, ha="center", va="center", fontsize=10, color="0.4")
            ax_tokens.set_ylim(-1.0, 1.0)

        ax.set_xlim(t0, t1)
        ax.grid(True, alpha=0.3)
        ax.set_ylabel(col)
        ax.set_title(f"{question_label} | window {t0:.1f}–{t1:.1f} s", loc="left", fontsize=11)
        handles, labels = ax.get_legend_handles_labels()
        if token_handle is not None:
            handles.append(token_handle)
            labels.append("Transcript tokens")
        ax.legend(handles, labels, loc="upper right")
        plt.setp(ax.get_xticklabels(), visible=False)

        ax_tokens.set_xlim(t0, t1)
        ax_tokens.set_xlabel("Time (s)")
        ax_tokens.set_ylabel("Token score")
        ax_tokens.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

        display_columns = ["word", "start", "end", "duration", "score", "canonical_value", "tr_value"]
        if not highlight_ranked.empty:
            display_df = highlight_ranked[display_columns].head(MAX_TOKENS_DISPLAY).reset_index(drop=True)
            if len(highlight_ranked) > MAX_TOKENS_DISPLAY:
                print(f"Showing top {MAX_TOKENS_DISPLAY} of {len(highlight_ranked)} tokens (sorted by score).")
        else:
            display_df = subset[display_columns].head(MAX_TOKENS_DISPLAY).reset_index(drop=True)
            if len(subset) > MAX_TOKENS_DISPLAY:
                print("No tokens matched the current filters; showing first tokens in window.")
        display(display_df)

    options = []
    for col, abbr in zip(qa_columns, qa_abbrevs):
        label = f"{col} | {abbr}" if abbr else col
        options.append((label, col))

    qa_dropdown = widgets.Dropdown(options=options, description="Question:", layout=widgets.Layout(width="45%"))
    window_slider = widgets.FloatRangeSlider(
        value=(0.0, min(120.0, float(canonical_time[-1]) if canonical_time.size else 0.0)),
        min=0.0,
        max=float(canonical_time[-1]) if canonical_time.size else 0.0,
        step=1.0,
        description="Window (s):",
        layout=widgets.Layout(width="70%")
    )
    threshold_slider = widgets.FloatSlider(
        value=min(0.05, QA_SCORE_ABS_MAX),
        min=0.0,
        max=max(0.1, QA_SCORE_ABS_MAX),
        step=0.01,
        readout_format=".2f",
        description="|score| ≥",
        layout=widgets.Layout(width="50%")
    )
    score_slider = widgets.FloatSlider(
        value=0.0,
        min=-1.0,
        max=1.0,
        step=0.01,
        readout_format=".2f",
        description="score ≥",
        layout=widgets.Layout(width="50%")
    )
    focus_peak_btn = widgets.Button(description="Focus on peak", icon="arrow-up")
    focus_trough_btn = widgets.Button(description="Focus on trough", icon="arrow-down")

    controls = widgets.VBox([
        qa_dropdown,
        window_slider,
        widgets.HBox([threshold_slider, score_slider]),
        widgets.HBox([focus_peak_btn, focus_trough_btn]),
    ])
    out = widgets.Output()

    def _update_alignment(*_):
        with out:
            out.clear_output()
            col = qa_dropdown.value
            t0, t1 = window_slider.value
            min_abs = float(threshold_slider.value)
            min_score = float(score_slider.value)
            subset = _prepare_subset(col, t0, t1)
            highlight = subset[subset["abs_score"] >= min_abs].copy()
            if min_score > score_slider.min + 1e-9:
                highlight = highlight[highlight["score"] >= min_score]
            _plot_alignment(col, subset, highlight, t0=t0, t1=t1, question_label=qa_name_lookup.get(col, col))

    def _focus_window(extreme: str):
        col = qa_dropdown.value
        scores = QA_SCORE_CACHE.get(col)
        if scores is None:
            return
        base = TOKEN_BASE_DF.copy()
        base["score"] = scores
        base = base[np.isfinite(base["score"])]
        if base.empty:
            return
        idx = base["score"].idxmax() if extreme == "high" else base["score"].idxmin()
        center = float(base.loc[idx, "midpoint"])
        half = 0.5 * FOCUS_WINDOW_SECONDS
        t0 = max(window_slider.min, center - half)
        t1 = min(window_slider.max, center + half)
        target_value = float(base.loc[idx, "score"])
        target_abs = abs(target_value)
        window_slider.value = (t0, t1)
        if target_abs > 0:
            new_threshold = min(threshold_slider.max, max(threshold_slider.min, target_abs * 0.6))
            threshold_slider.value = new_threshold
        if score_slider.value > target_value:
            score_slider.value = max(score_slider.min, target_value)
        _update_alignment()

    focus_peak_btn.on_click(lambda _: _focus_window("high"))
    focus_trough_btn.on_click(lambda _: _focus_window("low"))

    _update_alignment()
    for widget in (qa_dropdown, window_slider, threshold_slider, score_slider):
        widget.observe(_update_alignment, "value")

    display(controls, out)


__all__ = ["launch_alignment_explorer", "load_alignment_data", "abbreviate_question"]
