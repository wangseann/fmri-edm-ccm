{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c741834",
   "metadata": {},
   "source": [
    "# DayXX: QA-Emb Time Series\n",
    "\n",
    "Build QA-Emb question-wise time series for ds003020 transcripts (token n-grams → QA scores → 50 ms canonical smoothing → TR aggregation), with plots and a transcript/question alignment explorer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2842c9",
   "metadata": {},
   "source": [
    "Run the QA-Emb encoding on a GPU node (load cuda/python modules, activate .venv, set HF_TOKEN, ensure `torch.cuda.is_available()` is True); caching is enabled so once `/featurestest/qaemb/..._qaemb_tokens.npy` is written you can reload it instead of re-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/flash/PaoU/seann/fmri-edm-ccm\")\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import json, math, os, sys, warnings\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from src.utils import load_yaml\n",
    "from src.decoding import load_transcript_words\n",
    "from src.day19_category_builder import (\n",
    "    build_tr_edges,\n",
    "    tr_token_overlap,\n",
    "    build_smoothing_kernel,\n",
    "    apply_smoothing_kernel,\n",
    "    aggregate_seconds_to_edges,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad79d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_yaml('/flash/PaoU/seann/fmri-edm-ccm/configs/demo.yaml')\n",
    "paths = cfg.get('paths', {})\n",
    "TR = float(cfg.get('TR', 2.0))\n",
    "\n",
    "SUBJECT = cfg.get('subject') or 'UTS01'\n",
    "STORY = cfg.get('story') or 'wheretheressmoke'\n",
    "\n",
    "qa_cfg = cfg.get('qa_emb', {}) or {}\n",
    "QA_QUESTIONS_PATH = qa_cfg.get('questions_path', 'configs/qaemb_questions.json')\n",
    "QA_CHECKPOINT = qa_cfg.get('checkpoint', 'meta-llama/Meta-Llama-3-8B-Instruct')\n",
    "QA_NGRAM_SIZE = int(qa_cfg.get('ngram_size', 10))\n",
    "QA_USE_CACHE = bool(qa_cfg.get('use_cache', True))\n",
    "SECONDS_BIN_WIDTH = float(qa_cfg.get('seconds_bin_width', 0.05))\n",
    "SMOOTHING_SECONDS = float(qa_cfg.get('smoothing_seconds', 1.0))\n",
    "SMOOTHING_METHOD = qa_cfg.get('smoothing_method', 'moving_average')\n",
    "GAUSSIAN_SIGMA_SECONDS = qa_cfg.get('gaussian_sigma_seconds', 0.5 * SMOOTHING_SECONDS)\n",
    "SMOOTHING_PAD_MODE = qa_cfg.get('smoothing_pad_mode', 'reflect')\n",
    "SAVE_OUTPUTS = bool(qa_cfg.get('save_outputs', True))\n",
    "\n",
    "features_root = Path(paths.get('featurestest', 'featurestest')) / 'qaemb'\n",
    "features_root.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Using features root: {features_root}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0223eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_path = PROJECT_ROOT / QA_QUESTIONS_PATH\n",
    "if not questions_path.exists():\n",
    "    raise FileNotFoundError(f'QA question file not found at {questions_path}')\n",
    "with questions_path.open() as fh:\n",
    "    QA_QUESTIONS = json.load(fh)\n",
    "if not isinstance(QA_QUESTIONS, list) or not all(isinstance(q, str) for q in QA_QUESTIONS):\n",
    "    raise ValueError('QA questions JSON must be a list of strings.')\n",
    "\n",
    "n_questions = len(QA_QUESTIONS)\n",
    "print(f'Loaded {n_questions} QA questions from {questions_path}')\n",
    "\n",
    "\n",
    "def abbreviate_question(q: str, max_words: int = 3) -> str:\n",
    "    q = str(q).strip()\n",
    "    if q.endswith('?'):\n",
    "        q = q[:-1]\n",
    "    words = q.split()\n",
    "    return ' '.join(words[:max_words])\n",
    "\n",
    "\n",
    "QA_ABBREVS = [abbreviate_question(q) for q in QA_QUESTIONS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f834dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_events = load_transcript_words(paths, SUBJECT, STORY)\n",
    "if not story_events:\n",
    "    raise ValueError(f'No transcript events found for {SUBJECT} {STORY}.')\n",
    "\n",
    "print(f'Loaded {len(story_events)} transcript tokens for {SUBJECT} / {STORY}.')\n",
    "\n",
    "token_df = pd.DataFrame(story_events, columns=['word', 'start', 'end'])\n",
    "token_df['word'] = token_df['word'].astype(str).str.strip()\n",
    "token_df['midpoint'] = 0.5 * (token_df['start'] + token_df['end'])\n",
    "token_df['token_index'] = np.arange(len(token_df))\n",
    "\n",
    "all_words = token_df['word'].tolist()\n",
    "\n",
    "\n",
    "def make_ngram_text(words: Sequence[str], i: int, n: int) -> str:\n",
    "    start = max(0, i - n + 1)\n",
    "    return ' '.join(words[start:i + 1])\n",
    "\n",
    "\n",
    "examples = [make_ngram_text(all_words, i, QA_NGRAM_SIZE) for i in range(len(all_words))]\n",
    "print(f'Prepared {len(examples)} QA-Emb inputs with ngram size {QA_NGRAM_SIZE}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3857e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from imodelsx import QAEmb\n",
    "except ImportError as exc:\n",
    "    raise ImportError('Install imodelsx to run QA-Emb encoding (e.g., `pip install imodelsx`).') from exc\n",
    "\n",
    "# Ensure HF token is available for gated checkpoints\n",
    "os.environ.setdefault(\"HF_TOKEN\", \"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\")\n",
    "\n",
    "QA_USE_CACHE = True  # force caching for expensive QAEmb encoding\n",
    "\n",
    "qa_root = features_root / 'tokens' / SUBJECT\n",
    "qa_root.mkdir(parents=True, exist_ok=True)\n",
    "qa_file = qa_root / f'{STORY}_qaemb_tokens.npy'\n",
    "qa_questions_out = qa_root / f'{STORY}_qaemb_questions.json'\n",
    "\n",
    "print(f\"cuda_available: {torch.cuda.is_available()}\")\n",
    "\n",
    "qa_matrix = None\n",
    "if qa_file.exists():\n",
    "    cached = np.load(qa_file)\n",
    "    if cached.shape == (len(token_df), n_questions):\n",
    "        qa_matrix = cached\n",
    "        print(f'Loaded cached QA embeddings from {qa_file}')\n",
    "    else:\n",
    "        warnings.warn(f'Cached QA embeddings had shape {cached.shape}; expected {(len(token_df), n_questions)}. Recomputing.')\n",
    "\n",
    "if qa_matrix is None:\n",
    "    if \"HF_TOKEN\" not in os.environ:\n",
    "        warnings.warn('HF_TOKEN is not set; gated checkpoints will fail. Set it before rerunning.')\n",
    "    embedder = QAEmb(\n",
    "        questions=QA_QUESTIONS,\n",
    "        checkpoint=QA_CHECKPOINT,\n",
    "        use_cache=QA_USE_CACHE,\n",
    "    )\n",
    "\n",
    "    BATCH_SIZE = 128\n",
    "    qa_rows = []\n",
    "    for start in range(0, len(examples), BATCH_SIZE):\n",
    "        batch = examples[start:start + BATCH_SIZE]\n",
    "        emb = embedder(batch)\n",
    "        qa_rows.append(np.asarray(emb, dtype=float))\n",
    "\n",
    "    qa_matrix = np.vstack(qa_rows) if qa_rows else np.empty((0, n_questions), dtype=float)\n",
    "    np.save(qa_file, qa_matrix)\n",
    "    with qa_questions_out.open('w') as fh:\n",
    "        json.dump(QA_QUESTIONS, fh, indent=2)\n",
    "    print(f'Saved token-level QA features to {qa_file}')\n",
    "else:\n",
    "    if not qa_questions_out.exists():\n",
    "        with qa_questions_out.open('w') as fh:\n",
    "            json.dump(QA_QUESTIONS, fh, indent=2)\n",
    "\n",
    "assert qa_matrix.shape[0] == len(token_df), 'QA matrix rows must match tokens.'\n",
    "assert qa_matrix.shape[1] == n_questions, 'QA matrix columns must match question count.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_edges = build_tr_edges(story_events, TR)\n",
    "\n",
    "max_end_time = float(token_df['end'].max())\n",
    "canonical_edges = np.arange(0.0, max_end_time + SECONDS_BIN_WIDTH, SECONDS_BIN_WIDTH, dtype=float)\n",
    "if canonical_edges[-1] < max_end_time:\n",
    "    canonical_edges = np.append(canonical_edges, canonical_edges[-1] + SECONDS_BIN_WIDTH)\n",
    "if canonical_edges[-1] < max_end_time - 1e-9:\n",
    "    canonical_edges = np.append(canonical_edges, canonical_edges[-1] + SECONDS_BIN_WIDTH)\n",
    "\n",
    "assert np.all(np.diff(canonical_edges) > 0), 'Non-monotone canonical edges.'\n",
    "print(f'Canonical bins: {len(canonical_edges) - 1}, TR bins: {len(tr_edges) - 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_records: List[Dict] = []\n",
    "for i, row in token_df.iterrows():\n",
    "    event_records.append(\n",
    "        {\n",
    "            'word': row['word'],\n",
    "            'start': float(row['start']),\n",
    "            'end': float(row['end']),\n",
    "            'qa_vec': qa_matrix[i].astype(float),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def build_token_buckets(edges: np.ndarray, event_records: Sequence[Dict], mode: str = 'proportional') -> List[List[Dict]]:\n",
    "    if edges.size < 2:\n",
    "        return []\n",
    "    buckets: List[List[Dict]] = [[] for _ in range(len(edges) - 1)]\n",
    "    for rec in event_records:\n",
    "        start = rec['start']\n",
    "        end = rec['end']\n",
    "        if end <= edges[0] or start >= edges[-1]:\n",
    "            continue\n",
    "        start_idx = max(0, int(np.searchsorted(edges, start, side='right')) - 1)\n",
    "        end_idx = max(0, int(np.searchsorted(edges, end, side='left')))\n",
    "        end_idx = min(end_idx, len(buckets) - 1)\n",
    "        for idx in range(start_idx, end_idx + 1):\n",
    "            bucket_start = edges[idx]\n",
    "            bucket_end = edges[idx + 1]\n",
    "            overlap = tr_token_overlap(start, end, bucket_start, bucket_end, 'proportional')\n",
    "            if overlap <= 0:\n",
    "                continue\n",
    "            item = {\n",
    "                'word': rec['word'],\n",
    "                'overlap': overlap,\n",
    "                'token_start': start,\n",
    "                'token_end': end,\n",
    "                'bucket_start': bucket_start,\n",
    "                'bucket_end': bucket_end,\n",
    "            }\n",
    "            if 'qa_vec' in rec:\n",
    "                item['qa_vec'] = rec['qa_vec']\n",
    "            buckets[idx].append(item)\n",
    "    return buckets\n",
    "\n",
    "\n",
    "canonical_buckets = build_token_buckets(canonical_edges, event_records, mode='proportional')\n",
    "tr_buckets = build_token_buckets(tr_edges, event_records, mode='proportional')\n",
    "print(\n",
    "    f'Canonical bins without tokens: {sum(1 for b in canonical_buckets if not b)}/{len(canonical_buckets)}; '\n",
    "    f'TR bins without tokens: {sum(1 for b in tr_buckets if not b)}/{len(tr_buckets)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_qa_time_series(\n",
    "    edges: np.ndarray,\n",
    "    buckets: Sequence[Sequence[Dict]],\n",
    "    n_questions: int,\n",
    "    *,\n",
    "    index_name: str = 'bin_index',\n",
    "    prefix: str = 'qa_q',\n",
    "):\n",
    "    n_bins = len(buckets)\n",
    "    qa_ts = np.full((n_bins, n_questions), np.nan, dtype=float)\n",
    "    for i, bucket in enumerate(buckets):\n",
    "        if not bucket:\n",
    "            continue\n",
    "        num = np.zeros(n_questions, dtype=float)\n",
    "        denom = 0.0\n",
    "        for item in bucket:\n",
    "            qa_vec = item.get('qa_vec')\n",
    "            if qa_vec is None:\n",
    "                continue\n",
    "            w = float(item.get('overlap', 1.0))\n",
    "            num += qa_vec * w\n",
    "            denom += w\n",
    "        if denom > 0:\n",
    "            qa_ts[i] = num / denom\n",
    "    data = {\n",
    "        index_name: np.arange(n_bins, dtype=int),\n",
    "        'start_sec': edges[:-1],\n",
    "        'end_sec': edges[1:],\n",
    "    }\n",
    "    cols = []\n",
    "    for j in range(n_questions):\n",
    "        col = f'{prefix}{j:03d}'\n",
    "        data[col] = qa_ts[:, j]\n",
    "        cols.append(col)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df, qa_ts, cols\n",
    "\n",
    "\n",
    "canonical_df_raw, canonical_matrix, qa_columns = score_qa_time_series(\n",
    "    canonical_edges,\n",
    "    canonical_buckets,\n",
    "    n_questions,\n",
    "    index_name='bin_index',\n",
    "    prefix='qa_q',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68b0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing_kernel = build_smoothing_kernel(\n",
    "    SECONDS_BIN_WIDTH,\n",
    "    SMOOTHING_SECONDS,\n",
    "    method=SMOOTHING_METHOD,\n",
    "    gaussian_sigma_seconds=GAUSSIAN_SIGMA_SECONDS,\n",
    ")\n",
    "smoothing_applied = smoothing_kernel.size > 1\n",
    "\n",
    "canonical_values_raw = canonical_matrix.copy()\n",
    "if canonical_values_raw.size and smoothing_applied:\n",
    "    canonical_values_smoothed = apply_smoothing_kernel(canonical_values_raw, smoothing_kernel, pad_mode=SMOOTHING_PAD_MODE)\n",
    "else:\n",
    "    canonical_values_smoothed = canonical_values_raw.copy()\n",
    "\n",
    "canonical_df_smoothed = canonical_df_raw.copy()\n",
    "if qa_columns:\n",
    "    canonical_df_smoothed.loc[:, qa_columns] = canonical_values_smoothed\n",
    "canonical_df_selected = canonical_df_smoothed if smoothing_applied else canonical_df_raw\n",
    "print(f'Smoothing kernel length: {len(smoothing_kernel)} (applied={smoothing_applied})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_values_raw = aggregate_seconds_to_edges(canonical_edges, canonical_values_raw, tr_edges)\n",
    "tr_values_smoothed = aggregate_seconds_to_edges(canonical_edges, canonical_values_smoothed, tr_edges)\n",
    "\n",
    "base_index = np.arange(len(tr_edges) - 1, dtype=int)\n",
    "base_df = pd.DataFrame({'tr_index': base_index, 'start_sec': tr_edges[:-1], 'end_sec': tr_edges[1:]})\n",
    "\n",
    "tr_df_raw = base_df.copy()\n",
    "tr_df_smoothed = base_df.copy()\n",
    "if qa_columns:\n",
    "    tr_df_raw.loc[:, qa_columns] = tr_values_raw\n",
    "    tr_df_smoothed.loc[:, qa_columns] = tr_values_smoothed\n",
    "tr_df_selected = tr_df_smoothed if smoothing_applied else tr_df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773eb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root = features_root / 'subjects' / SUBJECT / STORY\n",
    "canonical_root = features_root / 'stories' / STORY\n",
    "\n",
    "if SAVE_OUTPUTS:\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "    canonical_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    canonical_csv = canonical_root / 'qaemb_timeseries_seconds.csv'\n",
    "    canonical_df_selected.to_csv(canonical_csv, index=False)\n",
    "    if smoothing_applied:\n",
    "        canonical_df_raw.to_csv(canonical_root / 'qaemb_timeseries_seconds_raw.csv', index=False)\n",
    "\n",
    "    tr_csv = output_root / 'qaemb_timeseries.csv'\n",
    "    tr_df_selected.to_csv(tr_csv, index=False)\n",
    "    if smoothing_applied:\n",
    "        tr_df_raw.to_csv(output_root / 'qaemb_timeseries_raw.csv', index=False)\n",
    "\n",
    "    meta = {\n",
    "        'subject': SUBJECT,\n",
    "        'story': STORY,\n",
    "        'tr_seconds': TR,\n",
    "        'seconds_bin_width': SECONDS_BIN_WIDTH,\n",
    "        'smoothing_seconds': SMOOTHING_SECONDS,\n",
    "        'smoothing_method': SMOOTHING_METHOD,\n",
    "        'gaussian_sigma_seconds': GAUSSIAN_SIGMA_SECONDS,\n",
    "        'smoothing_pad_mode': SMOOTHING_PAD_MODE,\n",
    "        'questions_path': str(questions_path),\n",
    "        'checkpoint': QA_CHECKPOINT,\n",
    "        'n_questions': n_questions,\n",
    "        'ngram_size': QA_NGRAM_SIZE,\n",
    "    }\n",
    "    with (output_root / 'qaemb_metadata.json').open('w') as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f'Saved canonical QA series to {canonical_csv}Saved TR QA series to {tr_csv}')\n",
    "else:\n",
    "    print('Skipping save (SAVE_OUTPUTS is False).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb51aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_time = 0.5 * (canonical_edges[:-1] + canonical_edges[1:])\n",
    "tr_time = tr_edges[:-1]\n",
    "\n",
    "def plot_qa_series(selected_cols):\n",
    "    if not selected_cols:\n",
    "        print('No QA columns selected.')\n",
    "        return\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for col in selected_cols:\n",
    "        plt.plot(canonical_time, canonical_df_selected[col], label=f'{col} canonical', linewidth=1.4)\n",
    "        plt.plot(tr_time, tr_df_selected[col], label=f'{col} TR', linestyle='--', marker='.', markersize=3)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('QA score')\n",
    "    plt.title(f'{SUBJECT} / {STORY} | smoothing={SMOOTHING_METHOD} ({SMOOTHING_SECONDS}s)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "default_cols = qa_columns[: min(3, len(qa_columns))]\n",
    "if widgets is not None:\n",
    "    selector = widgets.SelectMultiple(options=qa_columns, value=tuple(default_cols), description='Questions:', layout=widgets.Layout(width='40%'))\n",
    "    out = widgets.Output()\n",
    "    display(selector, out)\n",
    "\n",
    "    def _update(*_):\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            plot_qa_series(list(selector.value))\n",
    "\n",
    "    selector.observe(_update, 'value')\n",
    "    _update()\n",
    "else:\n",
    "    plot_qa_series(default_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "if widgets is None:\n",
    "    raise RuntimeError('ipywidgets unavailable; install ipywidgets to use the alignment explorer.')\n",
    "\n",
    "TOKEN_BASE_DF = token_df[['token_index', 'word', 'start', 'end', 'midpoint']].copy()\n",
    "TOKEN_BASE_DF['duration'] = TOKEN_BASE_DF['end'] - TOKEN_BASE_DF['start']\n",
    "QA_SCORE_CACHE = {col: qa_matrix[:, idx].astype(float) for idx, col in enumerate(qa_columns)}\n",
    "QA_SCORE_ABS_MAX = float(np.nanmax(np.abs(qa_matrix))) if qa_matrix.size else 0.0\n",
    "\n",
    "canonical_time = 0.5 * (canonical_edges[:-1] + canonical_edges[1:])\n",
    "tr_time = tr_edges[:-1]\n",
    "qa_name_lookup = {col: QA_QUESTIONS[idx] if idx < len(QA_QUESTIONS) else col for idx, col in enumerate(qa_columns)}\n",
    "MAX_TOKENS_DISPLAY = 60\n",
    "FOCUS_WINDOW_SECONDS = 20.0\n",
    "\n",
    "\n",
    "def _interpolate_series(series_values: pd.Series, times: np.ndarray, query: np.ndarray) -> np.ndarray:\n",
    "    values = np.asarray(series_values, dtype=float)\n",
    "    times = np.asarray(times, dtype=float)\n",
    "    query = np.asarray(query, dtype=float)\n",
    "    finite = np.isfinite(values)\n",
    "    if finite.sum() < 2:\n",
    "        return np.full(query.shape, np.nan, dtype=float)\n",
    "    interp = np.interp(query, times[finite], values[finite])\n",
    "    interp[(query < times[finite][0]) | (query > times[finite][-1])] = np.nan\n",
    "    return interp\n",
    "\n",
    "\n",
    "def _prepare_subset(col: str, t0: float, t1: float) -> pd.DataFrame:\n",
    "    mask = (TOKEN_BASE_DF['midpoint'] >= t0) & (TOKEN_BASE_DF['midpoint'] <= t1)\n",
    "    subset = TOKEN_BASE_DF.loc[mask].copy()\n",
    "    scores = QA_SCORE_CACHE.get(col)\n",
    "    if scores is None:\n",
    "        raise RuntimeError(f'No cached scores for {col}')\n",
    "    subset['score'] = scores[mask.to_numpy()]\n",
    "    subset['abs_score'] = subset['score'].abs()\n",
    "    subset.sort_values('start', inplace=True)\n",
    "    subset['canonical_value'] = _interpolate_series(canonical_df_selected[col], canonical_time, subset['midpoint'].to_numpy())\n",
    "    subset['tr_value'] = _interpolate_series(tr_df_selected[col], tr_time, subset['midpoint'].to_numpy())\n",
    "    return subset\n",
    "\n",
    "\n",
    "def _plot_alignment(col: str, subset: pd.DataFrame, highlight: pd.DataFrame, *, t0: float, t1: float, question_label: str):\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    highlight_ranked = highlight.sort_values('score', ascending=False)\n",
    "    if len(highlight_ranked) > MAX_TOKENS_DISPLAY:\n",
    "        plot_highlight = highlight_ranked.head(MAX_TOKENS_DISPLAY).sort_values('midpoint')\n",
    "    else:\n",
    "        plot_highlight = highlight_ranked.sort_values('midpoint')\n",
    "\n",
    "    series_canon = canonical_df_selected[col].to_numpy(dtype=float)\n",
    "    series_tr = tr_df_selected[col].to_numpy(dtype=float)\n",
    "    max_abs = float(np.nanmax(np.abs(subset['score'].to_numpy()))) if subset['score'].notna().any() else 1.0\n",
    "    max_abs = max(max_abs, 1.0)\n",
    "\n",
    "    fig = plt.figure(figsize=(14, 5))\n",
    "    gs = fig.add_gridspec(2, 1, height_ratios=[3, 1], hspace=0.12)\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    ax_tokens = fig.add_subplot(gs[1], sharex=ax)\n",
    "\n",
    "    canon_mask = (canonical_time >= t0) & (canonical_time <= t1)\n",
    "    tr_mask = (tr_time >= t0) & (tr_time <= t1)\n",
    "    ax.plot(canonical_time[canon_mask], series_canon[canon_mask], color='tab:blue', label='Canonical (smoothed)')\n",
    "    ax.plot(tr_time[tr_mask], series_tr[tr_mask], color='tab:orange', label='TR (smoothed)')\n",
    "\n",
    "    token_handle = None\n",
    "    if not plot_highlight.empty:\n",
    "        scale = float(np.nanmax(plot_highlight['abs_score'].to_numpy())) if plot_highlight['abs_score'].notna().any() else 0.0\n",
    "        scale = scale if scale > 0 else 1.0\n",
    "        colors = np.where(plot_highlight['score'] >= 0, 'tab:green', 'tab:red')\n",
    "        sizes = 60 + 200 * (plot_highlight['abs_score'] / scale)\n",
    "        ax.scatter(plot_highlight['midpoint'], plot_highlight['canonical_value'], s=sizes, c=colors, alpha=0.9, edgecolor='white', linewidth=0.4)\n",
    "        token_handle = mlines.Line2D([], [], marker='o', linestyle='None', color='tab:green', markerfacecolor='tab:green', markeredgecolor='white', label='Transcript tokens')\n",
    "\n",
    "        ax_tokens.axhline(0.0, color='0.6', linewidth=1.0)\n",
    "        ax_tokens.vlines(plot_highlight['midpoint'], 0.0, plot_highlight['score'], colors=colors, linewidth=2.0, alpha=0.8)\n",
    "        for row in plot_highlight.itertuples():\n",
    "            y = row.score\n",
    "            offset = 0.04 * max_abs\n",
    "            text_y = y + offset if y >= 0 else y - offset\n",
    "            va = 'bottom' if y >= 0 else 'top'\n",
    "            ax_tokens.text(row.midpoint, text_y, row.word, rotation=90, ha='center', va=va, fontsize=8)\n",
    "        ax_tokens.set_ylim(-max_abs * 1.3, max_abs * 1.3)\n",
    "    else:\n",
    "        ax_tokens.axhline(0.0, color='0.6', linewidth=1.0)\n",
    "        ax_tokens.text(0.5, 0.5, 'No tokens matched the current filters', transform=ax_tokens.transAxes, ha='center', va='center', fontsize=10, color='0.4')\n",
    "        ax_tokens.set_ylim(-1.0, 1.0)\n",
    "\n",
    "    ax.set_xlim(t0, t1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylabel(col)\n",
    "    ax.set_title(f'{question_label} | window {t0:.1f}–{t1:.1f} s', loc='left', fontsize=11)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if token_handle is not None:\n",
    "        handles.append(token_handle)\n",
    "        labels.append('Transcript tokens')\n",
    "    ax.legend(handles, labels, loc='upper right')\n",
    "    plt.setp(ax.get_xticklabels(), visible=False)\n",
    "\n",
    "    ax_tokens.set_xlim(t0, t1)\n",
    "    ax_tokens.set_xlabel('Time (s)')\n",
    "    ax_tokens.set_ylabel('Token score')\n",
    "    ax_tokens.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    display_columns = ['word', 'start', 'end', 'duration', 'score', 'canonical_value', 'tr_value']\n",
    "    if not highlight_ranked.empty:\n",
    "        display_df = highlight_ranked[display_columns].head(MAX_TOKENS_DISPLAY).reset_index(drop=True)\n",
    "        if len(highlight_ranked) > MAX_TOKENS_DISPLAY:\n",
    "            print(f'Showing top {MAX_TOKENS_DISPLAY} of {len(highlight_ranked)} tokens (sorted by score).')\n",
    "    else:\n",
    "        display_df = subset[display_columns].head(MAX_TOKENS_DISPLAY).reset_index(drop=True)\n",
    "        if len(subset) > MAX_TOKENS_DISPLAY:\n",
    "            print('No tokens matched the current filters; showing first tokens in window.')\n",
    "    display(display_df)\n",
    "\n",
    "\n",
    "options = []\n",
    "for col, abbr in zip(qa_columns, QA_ABBREVS):\n",
    "    label = f\"{col} | {abbr}\" if abbr else col\n",
    "    options.append((label, col))\n",
    "\n",
    "qa_dropdown = widgets.Dropdown(options=options, description='Question:', layout=widgets.Layout(width='45%'))\n",
    "window_slider = widgets.FloatRangeSlider(\n",
    "    value=(0.0, min(120.0, float(canonical_time[-1]))),\n",
    "    min=0.0,\n",
    "    max=float(canonical_time[-1]),\n",
    "    step=1.0,\n",
    "    description='Window (s):',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=min(0.05, QA_SCORE_ABS_MAX),\n",
    "    min=0.0,\n",
    "    max=max(0.1, QA_SCORE_ABS_MAX),\n",
    "    step=0.01,\n",
    "    readout_format='.2f',\n",
    "    description='|score| ≥',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "score_slider = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=-1.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    readout_format='.2f',\n",
    "    description='score ≥',\n",
    "    layout=widgets.Layout(width='50%')\n",
    ")\n",
    "focus_peak_btn = widgets.Button(description='Focus on peak', icon='arrow-up')\n",
    "focus_trough_btn = widgets.Button(description='Focus on trough', icon='arrow-down')\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    qa_dropdown,\n",
    "    window_slider,\n",
    "    widgets.HBox([threshold_slider, score_slider]),\n",
    "    widgets.HBox([focus_peak_btn, focus_trough_btn]),\n",
    "])\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "def _update_alignment(*_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        col = qa_dropdown.value\n",
    "        t0, t1 = window_slider.value\n",
    "        min_abs = float(threshold_slider.value)\n",
    "        min_score = float(score_slider.value)\n",
    "        subset = _prepare_subset(col, t0, t1)\n",
    "        highlight = subset[subset['abs_score'] >= min_abs].copy()\n",
    "        if min_score > score_slider.min + 1e-9:\n",
    "            highlight = highlight[highlight['score'] >= min_score]\n",
    "        _plot_alignment(col, subset, highlight, t0=t0, t1=t1, question_label=qa_name_lookup.get(col, col))\n",
    "\n",
    "\n",
    "def _focus_window(extreme: str):\n",
    "    col = qa_dropdown.value\n",
    "    scores = QA_SCORE_CACHE.get(col)\n",
    "    if scores is None:\n",
    "        return\n",
    "    base = TOKEN_BASE_DF.copy()\n",
    "    base['score'] = scores\n",
    "    base = base[np.isfinite(base['score'])]\n",
    "    if base.empty:\n",
    "        return\n",
    "    idx = base['score'].idxmax() if extreme == 'high' else base['score'].idxmin()\n",
    "    center = float(base.loc[idx, 'midpoint'])\n",
    "    half = 0.5 * FOCUS_WINDOW_SECONDS\n",
    "    t0 = max(window_slider.min, center - half)\n",
    "    t1 = min(window_slider.max, center + half)\n",
    "    target_value = float(base.loc[idx, 'score'])\n",
    "    target_abs = abs(target_value)\n",
    "    window_slider.value = (t0, t1)\n",
    "    if target_abs > 0:\n",
    "        new_threshold = min(threshold_slider.max, max(threshold_slider.min, target_abs * 0.6))\n",
    "        threshold_slider.value = new_threshold\n",
    "    if score_slider.value > target_value:\n",
    "        score_slider.value = max(score_slider.min, target_value)\n",
    "    _update_alignment()\n",
    "\n",
    "focus_peak_btn.on_click(lambda _: _focus_window('high'))\n",
    "focus_trough_btn.on_click(lambda _: _focus_window('low'))\n",
    "\n",
    "_update_alignment()\n",
    "for widget in (qa_dropdown, window_slider, threshold_slider, score_slider):\n",
    "    widget.observe(_update_alignment, 'value')\n",
    "\n",
    "display(controls, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
