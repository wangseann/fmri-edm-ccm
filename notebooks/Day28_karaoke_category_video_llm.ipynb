{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3702e4",
   "metadata": {},
   "source": [
    "# Day 28 - Karaoke Category Video (LLM embeddings)\n",
    "\n",
    "This notebook rebuilds category time series using LLM embeddings and renders a\n",
    "karaoke-style MP4 with the active bin highlighted and its words listed at top.\n",
    "\n",
    "Workflow:\n",
    "1. Update the configuration cell (LM embedding path, subject/story, smoothing).\n",
    "2. Run the generation cell to create `result`.\n",
    "3. Run the token prep cell.\n",
    "4. Pick 12 categories for the grid.\n",
    "5. Run the video cell (requires ffmpeg).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.options.display.max_columns = 60\n",
    "\n",
    "project_root = Path('/flash/PaoU/seann/fmri-edm-ccm')\n",
    "project_root.mkdir(parents=True, exist_ok=True)\n",
    "os.chdir(project_root)\n",
    "\n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append('/flash/PaoU/seann/pyEDM/src')\n",
    "sys.path.append('/flash/PaoU/seann/MDE-main/src')\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    widgets = None\n",
    "    def display(obj):\n",
    "        print(obj)\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception as exc:\n",
    "    plt = None\n",
    "    warnings.warn(f'Matplotlib unavailable: {exc}')\n",
    "\n",
    "from src.utils import load_yaml\n",
    "from src.category_builder import generate_category_time_series, get_embedding_backend\n",
    "\n",
    "EPS = 1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2156e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration -------------------------------------------------------------------\n",
    "cfg = load_yaml('configs/demo.yaml')\n",
    "categories_cfg = cfg.get('categories', {}) or {}\n",
    "cluster_csv_path = categories_cfg.get('cluster_csv_path', '')\n",
    "prototype_weight_power = float(categories_cfg.get('prototype_weight_power', 1.0))\n",
    "seconds_bin_width_default = float(categories_cfg.get('seconds_bin_width', 0.05))\n",
    "temporal_weighting_default = str(categories_cfg.get('temporal_weighting', 'proportional')).lower()\n",
    "\n",
    "paths = cfg.get('paths', {})\n",
    "TR = float(cfg.get('TR', 2.0))\n",
    "features_root = Path(paths.get('featurestest', 'featurestest'))\n",
    "features_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUBJECT = cfg.get('subject') or 'UTS01'\n",
    "STORY = cfg.get('story') or 'wheretheressmoke'\n",
    "TEMPORAL_WEIGHTING = temporal_weighting_default  # {'proportional', 'none'}\n",
    "SECONDS_BIN_WIDTH = seconds_bin_width_default\n",
    "\n",
    "# LLM embedding settings (matches run_day26_smoothing_llm.slurm defaults)\n",
    "LM_EMBEDDING_PATH = Path(os.environ.get('LM_EMBEDDING_PATH', 'embeddings/gpt_tokens.npz'))\n",
    "LM_LOWERCASE_TOKENS = os.environ.get('LM_LOWERCASE_TOKENS', 'true').lower() == 'true'\n",
    "if not LM_EMBEDDING_PATH.is_absolute():\n",
    "    LM_EMBEDDING_PATH = (project_root / LM_EMBEDDING_PATH).resolve()\n",
    "if not LM_EMBEDDING_PATH.exists():\n",
    "    raise FileNotFoundError(f'LLM embedding file not found: {LM_EMBEDDING_PATH}')\n",
    "\n",
    "# canonical smoothing controls (edit to taste)\n",
    "SMOOTHING_SECONDS = 1.00            # shorter window preserves fast dynamics for forecasting\n",
    "SMOOTHING_METHOD = 'moving_average'       # {'moving_average', 'gaussian'}\n",
    "GAUSSIAN_SIGMA_SECONDS = 0.5 * SMOOTHING_SECONDS  # tie sigma to window length for EDM\n",
    "SMOOTHING_PAD_MODE = 'reflect'      # {'edge', 'reflect'}\n",
    "\n",
    "SAVE_OUTPUTS = True  # toggle off to skip writing CSVs\n",
    "\n",
    "# video settings\n",
    "VIDEO_DIR = features_root / 'videos'\n",
    "VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "KARAOKE_OUTPUT = str(VIDEO_DIR / f'karaoke_llm_{SUBJECT}_{STORY}.mp4')\n",
    "KARAOKE_USE_DOMAIN = 'tr'  # 'tr' or 'canonical'\n",
    "KARAOKE_FPS = 1\n",
    "KARAOKE_WINDOW_SEC = 30.0\n",
    "KARAOKE_PAD_LEFT_SEC = 0.5\n",
    "KARAOKE_PAD_RIGHT_SEC = 2.0\n",
    "KARAOKE_PLAYBACK_SPEED = 7.0  # 1.0 real-time; <1 slower; >1 faster\n",
    "KARAOKE_YLIM_PAD_FRAC = 0.05  # add 5% headroom to y-lims\n",
    "KARAOKE_ZSCORE = True  # z-score each category series before plotting\n",
    "KARAOKE_LOG_EVERY_FRAMES = None  # None -> log every ~5s of video time\n",
    "KARAOKE_BIN_WORDS_MAX = 30  # None to show all words in the bin\n",
    "KARAOKE_CATEGORY_COUNT = 12  # must be 12 for the 4x3 grid\n",
    "KARAOKE_CATEGORY_COLUMNS = None  # set to a list of 12 column names if desired\n",
    "\n",
    "print(f'Subject/story: {SUBJECT} / {STORY}')\n",
    "print(f'Cluster CSV: {cluster_csv_path or \"<none>\"}')\n",
    "print(f'Temporal weighting: {TEMPORAL_WEIGHTING}')\n",
    "print(f'Seconds bin width: {SECONDS_BIN_WIDTH}')\n",
    "print(f'Smoothing: {SMOOTHING_METHOD} | window={SMOOTHING_SECONDS}s | sigma={GAUSSIAN_SIGMA_SECONDS}')\n",
    "print(f'LLM embeddings: {LM_EMBEDDING_PATH} (lowercase={LM_LOWERCASE_TOKENS})')\n",
    "print(f'Video output: {KARAOKE_OUTPUT}')\n",
    "print(f'Video domain: {KARAOKE_USE_DOMAIN} | fps={KARAOKE_FPS} | window={KARAOKE_WINDOW_SEC}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83faca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_backend = get_embedding_backend(\n",
    "    'llm',\n",
    "    lm_embedding_path=LM_EMBEDDING_PATH,\n",
    "    lm_lowercase_tokens=LM_LOWERCASE_TOKENS,\n",
    ")\n",
    "\n",
    "result = generate_category_time_series(\n",
    "    SUBJECT,\n",
    "    STORY,\n",
    "    cfg_base=cfg,\n",
    "    categories_cfg_base=categories_cfg,\n",
    "    cluster_csv_path=cluster_csv_path,\n",
    "    temporal_weighting=TEMPORAL_WEIGHTING,\n",
    "    prototype_weight_power=prototype_weight_power,\n",
    "    smoothing_seconds=SMOOTHING_SECONDS,\n",
    "    smoothing_method=SMOOTHING_METHOD,\n",
    "    gaussian_sigma_seconds=GAUSSIAN_SIGMA_SECONDS,\n",
    "    smoothing_pad=SMOOTHING_PAD_MODE,\n",
    "    seconds_bin_width=SECONDS_BIN_WIDTH,\n",
    "    features_root=features_root,\n",
    "    paths=paths,\n",
    "    TR=TR,\n",
    "    embedding_backend=embedding_backend,\n",
    "    save_outputs=SAVE_OUTPUTS,\n",
    ")\n",
    "\n",
    "canonical_df = result['canonical_df_selected']\n",
    "tr_df = result['category_df_selected']\n",
    "print()\n",
    "print('Smoothing configuration:', result['smoothing'])\n",
    "print()\n",
    "print('Canonical preview:')\n",
    "display(canonical_df.head())\n",
    "print()\n",
    "print('TR-aligned preview:')\n",
    "display(tr_df.head())\n",
    "if result['trimmed_df'] is not None:\n",
    "    print()\n",
    "    print(f\"Trimmed window length: {len(result['trimmed_df'])} (max_lag_primary={result['max_lag_primary']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fec8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare transcript tokens and per-category scores\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if 'result' not in globals():\n",
    "    raise RuntimeError('Run the generation cell first to populate `result`.')\n",
    "\n",
    "_tokens_raw = result.get('event_records') or []\n",
    "if not _tokens_raw:\n",
    "    raise RuntimeError('No transcript events found - rerun upstream steps.')\n",
    "\n",
    "_category_states = result.get('category_states') or {}\n",
    "if not _category_states:\n",
    "    raise RuntimeError('Category states missing from result; rerun the generation cell.')\n",
    "\n",
    "_token_df = pd.DataFrame(_tokens_raw)\n",
    "_token_df = _token_df[['word', 'start', 'end', 'embedding', 'embedding_norm']].copy()\n",
    "_token_df['midpoint'] = 0.5 * (_token_df['start'] + _token_df['end'])\n",
    "_token_df['duration'] = _token_df['end'] - _token_df['start']\n",
    "_token_df['token_index'] = np.arange(len(_token_df))\n",
    "\n",
    "_score_method = str(result.get('category_score_method', 'similarity')).lower()\n",
    "_token_scores = {}\n",
    "_abs_max = 0.0\n",
    "for cat_name, state in _category_states.items():\n",
    "    scores = []\n",
    "    proto = state.get('prototype')\n",
    "    proto_norm = state.get('prototype_norm') or 0.0\n",
    "    lexicon = state.get('lexicon', {}) or {}\n",
    "    for rec in _tokens_raw:\n",
    "        word = rec['word']\n",
    "        if _score_method == 'count':\n",
    "            score = lexicon.get(word.lower(), np.nan)\n",
    "        else:\n",
    "            emb = rec.get('embedding')\n",
    "            emb_norm = rec.get('embedding_norm') or 0.0\n",
    "            if emb is None or proto is None or proto_norm <= 0 or emb_norm <= 0:\n",
    "                score = np.nan\n",
    "            else:\n",
    "                score = float(np.clip(np.dot(emb, proto) / (emb_norm * proto_norm), -1.0, 1.0))\n",
    "        scores.append(score)\n",
    "    arr = np.array(scores, dtype=float)\n",
    "    _token_scores[cat_name] = arr\n",
    "    finite = np.abs(arr[np.isfinite(arr)])\n",
    "    if finite.size:\n",
    "        _abs_max = max(_abs_max, float(finite.max()))\n",
    "\n",
    "TOKEN_BASE_DF = _token_df[['token_index', 'word', 'start', 'end', 'midpoint', 'duration']].copy()\n",
    "TOKEN_SCORE_CACHE = _token_scores\n",
    "TOKEN_SCORE_METHOD = _score_method\n",
    "TOKEN_SCORE_ABS_MAX = _abs_max if _abs_max > 0 else 1.0\n",
    "\n",
    "# Drop heavy objects from the temporary frame to free memory\n",
    "del _token_df\n",
    "del _tokens_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b22d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected categories: ['cat_abstract', 'cat_communal', 'cat_emotional', 'cat_locational', 'cat_mental', 'cat_numeric', 'cat_professional', 'cat_social', 'cat_tactile', 'cat_temporal', 'cat_violent', 'cat_visual']\n"
     ]
    }
   ],
   "source": [
    "# Pick 12 categories for the 4x3 grid (edit as needed)\n",
    "if KARAOKE_CATEGORY_COLUMNS is None:\n",
    "    category_cols_12 = result['category_columns'][:KARAOKE_CATEGORY_COUNT]\n",
    "else:\n",
    "    category_cols_12 = list(KARAOKE_CATEGORY_COLUMNS)\n",
    "\n",
    "if len(category_cols_12) != 12:\n",
    "    raise ValueError(f'Expected 12 categories, got {len(category_cols_12)}.')\n",
    "\n",
    "print('Selected categories:', category_cols_12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18dd3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "if plt is None:\n",
    "    raise RuntimeError('Matplotlib unavailable in this environment.')\n",
    "\n",
    "\n",
    "def make_karaoke_category_video(\n",
    "    *,\n",
    "    result: dict,\n",
    "    token_df: pd.DataFrame,\n",
    "    category_cols: list,\n",
    "    out_mp4: str = \"karaoke_categories.mp4\",\n",
    "    use_domain: str = \"tr\",          # \"tr\" or \"canonical\"\n",
    "    fps: int = 30,\n",
    "    window_sec: float = 30.0,        # how many seconds visible at once\n",
    "    pad_left_sec: float = 0.5,\n",
    "    pad_right_sec: float = 2.0,\n",
    "    log_every_frames: int | None = None,\n",
    "    playback_speed: float = 1.0,\n",
    "    ypad_frac: float = 0.05,\n",
    "    bin_words_max: int | None = 30,\n",
    "    zscore: bool = True,\n",
    "):\n",
    "    '''\n",
    "    Creates an MP4 where the top shows words within the active bin and bottom is a 4x3 grid.\n",
    "    Assumes token_df has columns: word,start,end,midpoint (like your TOKEN_BASE_DF).\n",
    "    '''\n",
    "\n",
    "    assert use_domain in {\"tr\", \"canonical\"}\n",
    "    assert len(category_cols) == 12, \"Pass exactly 12 categories for a 4x3 grid.\"\n",
    "\n",
    "    if playback_speed <= 0:\n",
    "        raise ValueError(\"playback_speed must be > 0.\")\n",
    "    if ypad_frac < 0:\n",
    "        raise ValueError(\"ypad_frac must be >= 0.\")\n",
    "    if bin_words_max is not None and bin_words_max <= 0:\n",
    "        raise ValueError(\"bin_words_max must be > 0 or None.\")\n",
    "\n",
    "    if not isinstance(zscore, bool):\n",
    "        raise ValueError(\"zscore must be a boolean.\")\n",
    "\n",
    "    if log_every_frames is None:\n",
    "        log_every_frames = max(1, int(fps * 5))\n",
    "\n",
    "    # --- Choose time base and series ---\n",
    "    if use_domain == \"canonical\":\n",
    "        df = result[\"canonical_df_selected\"]\n",
    "        t = 0.5 * (result[\"canonical_edges\"][:-1] + result[\"canonical_edges\"][1:])\n",
    "        edges = result[\"canonical_edges\"]\n",
    "    else:\n",
    "        df = result[\"category_df_selected\"]\n",
    "        t = result[\"tr_edges\"][:-1]\n",
    "        edges = result[\"tr_edges\"]\n",
    "\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    edges = np.asarray(edges, dtype=float)\n",
    "\n",
    "    # Determine video duration from transcript\n",
    "    t_end = float(token_df[\"end\"].max())\n",
    "    transcript_duration = t_end + pad_right_sec\n",
    "    duration = transcript_duration / playback_speed\n",
    "    n_frames = int(np.ceil(duration * fps))\n",
    "\n",
    "    # Pre-extract series arrays for speed\n",
    "    Y = np.vstack([df[c].to_numpy(dtype=float) for c in category_cols])  # shape (12, T)\n",
    "\n",
    "    if zscore:\n",
    "        means = np.nanmean(Y, axis=1, keepdims=True)\n",
    "        stds = np.nanstd(Y, axis=1, keepdims=True)\n",
    "        stds = np.where(np.isfinite(stds) & (stds > 0), stds, 1.0)\n",
    "        Y = (Y - means) / stds\n",
    "\n",
    "    # Robust y-lims per subplot (full range with padding)\n",
    "    ylims = []\n",
    "    for i in range(12):\n",
    "        vals = Y[i]\n",
    "        finite = vals[np.isfinite(vals)]\n",
    "        if finite.size == 0:\n",
    "            ylims.append((-1, 1))\n",
    "        else:\n",
    "            lo = float(np.min(finite))\n",
    "            hi = float(np.max(finite))\n",
    "            if np.isclose(lo, hi):\n",
    "                pad = 1.0 if lo == 0 else abs(lo) * 0.1\n",
    "            else:\n",
    "                pad = (hi - lo) * ypad_frac\n",
    "            ylims.append((lo - pad, hi + pad))\n",
    "\n",
    "    # --- Figure layout: top karaoke + 4x3 plots ---\n",
    "    fig = plt.figure(figsize=(16, 9), dpi=150)\n",
    "    gs = fig.add_gridspec(5, 3, height_ratios=[0.65, 1, 1, 1, 1], hspace=0.35, wspace=0.25)\n",
    "\n",
    "    ax_text = fig.add_subplot(gs[0, :])\n",
    "    ax_text.axis(\"off\")\n",
    "\n",
    "    axes = []\n",
    "    for r in range(1, 5):\n",
    "        for c in range(3):\n",
    "            axes.append(fig.add_subplot(gs[r, c]))\n",
    "\n",
    "    # Initialize lines\n",
    "    lines = []\n",
    "    cursors = []\n",
    "    highlights = []\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.set_title(category_cols[i].replace(\"cat_\", \"\"), fontsize=10)\n",
    "        ax.set_xlim(0, window_sec)\n",
    "        ax.set_ylim(*ylims[i])\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        (ln,) = ax.plot([], [], linewidth=1.6)\n",
    "        cursor = ax.axvline(0, linewidth=1.2, alpha=0.9)\n",
    "        highlight = mpatches.Rectangle(\n",
    "            (0, 0), 0, 1,\n",
    "            transform=ax.get_xaxis_transform(),\n",
    "            facecolor=\"#f4c542\",\n",
    "            alpha=0.25,\n",
    "            zorder=0,\n",
    "        )\n",
    "        ax.add_patch(highlight)\n",
    "        lines.append(ln)\n",
    "        cursors.append(cursor)\n",
    "        highlights.append(highlight)\n",
    "\n",
    "    # Text artists\n",
    "    txt_bin = ax_text.text(0.01, 0.72, \"\", fontsize=16, fontweight=\"bold\", va=\"center\", ha=\"left\")\n",
    "    txt_words = ax_text.text(0.01, 0.36, \"\", fontsize=14, va=\"center\", ha=\"left\")\n",
    "    txt_sub  = ax_text.text(0.01, 0.10, \"\", fontsize=11, va=\"center\", ha=\"left\", alpha=0.8)\n",
    "\n",
    "    words = token_df[\"word\"].astype(str).tolist()\n",
    "    starts = token_df[\"start\"].to_numpy(dtype=float)\n",
    "    ends = token_df[\"end\"].to_numpy(dtype=float)\n",
    "\n",
    "    start_time = None\n",
    "\n",
    "    def _bin_index(t_now: float) -> int:\n",
    "        idx = int(np.searchsorted(edges, t_now, side=\"right\") - 1)\n",
    "        return int(np.clip(idx, 0, len(edges) - 2))\n",
    "\n",
    "    def _format_bin_words(bin_words: list[str]) -> str:\n",
    "        if not bin_words:\n",
    "            return \"(no words in bin)\"\n",
    "        if bin_words_max is not None and len(bin_words) > bin_words_max:\n",
    "            shown = bin_words[:bin_words_max]\n",
    "            return \" \".join(shown) + \" ...\"\n",
    "        return \" \".join(bin_words)\n",
    "\n",
    "    def init():\n",
    "        for ln in lines:\n",
    "            ln.set_data([], [])\n",
    "        txt_bin.set_text(\"\")\n",
    "        txt_words.set_text(\"\")\n",
    "        txt_sub.set_text(\"\")\n",
    "        return lines + cursors + highlights + [txt_bin, txt_words, txt_sub]\n",
    "\n",
    "    def update(frame):\n",
    "        nonlocal start_time\n",
    "        if start_time is None:\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "        t_now = (frame / fps) * playback_speed\n",
    "\n",
    "        # sliding window\n",
    "        w0 = max(0.0, t_now - window_sec + pad_left_sec)\n",
    "        w1 = w0 + window_sec\n",
    "\n",
    "        # slice series in the window (by time array)\n",
    "        mask = (t >= w0) & (t <= w1)\n",
    "        if not np.any(mask):\n",
    "            return lines + cursors + highlights + [txt_bin, txt_words, txt_sub]\n",
    "\n",
    "        tw = t[mask] - w0  # shift to window coords\n",
    "\n",
    "        bin_idx = _bin_index(t_now)\n",
    "        bin_start = float(edges[bin_idx])\n",
    "        bin_end = float(edges[bin_idx + 1])\n",
    "\n",
    "        view_start = max(bin_start, w0)\n",
    "        view_end = min(bin_end, w1)\n",
    "        span_start = view_start - w0\n",
    "        span_width = max(0.0, view_end - view_start)\n",
    "\n",
    "        for i in range(12):\n",
    "            yw = Y[i, mask]\n",
    "            lines[i].set_data(tw, yw)\n",
    "            cursors[i].set_xdata([t_now - w0, t_now - w0])\n",
    "            axes[i].set_xlim(0, window_sec)\n",
    "            highlights[i].set_x(span_start)\n",
    "            highlights[i].set_width(span_width)\n",
    "\n",
    "        bin_mask = (starts < bin_end) & (ends > bin_start)\n",
    "        bin_words = [words[i] for i in np.where(bin_mask)[0]]\n",
    "        words_text = _format_bin_words(bin_words)\n",
    "\n",
    "        txt_bin.set_text(\n",
    "            f\"Bin {bin_start:6.2f}-{bin_end:6.2f}s | {len(bin_words)} words\"\n",
    "        )\n",
    "        txt_words.set_text(words_text)\n",
    "        txt_sub.set_text(\n",
    "            f\"t = {t_now:6.2f}s | bin {bin_idx + 1}/{len(edges) - 1} | domain: {use_domain}\"\n",
    "        )\n",
    "\n",
    "        if frame % log_every_frames == 0 or frame == n_frames - 1:\n",
    "            elapsed = time.perf_counter() - start_time\n",
    "            progress = (frame + 1) / n_frames\n",
    "            eta = elapsed / progress - elapsed if progress > 0 else float('inf')\n",
    "            print(\n",
    "                f\"Frame {frame + 1}/{n_frames} \"\n",
    "                f\"({progress * 100:.1f}%) | \"\n",
    "                f\"elapsed {elapsed / 60:.1f}m | ETA {eta / 60:.1f}m\"\n",
    "            )\n",
    "\n",
    "        return lines + cursors + highlights + [txt_bin, txt_words, txt_sub]\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update, init_func=init,\n",
    "        frames=n_frames, interval=1000/fps, blit=False\n",
    "    )\n",
    "\n",
    "    writer = animation.FFMpegWriter(\n",
    "        fps=fps,\n",
    "        codec=\"libx264\",\n",
    "        bitrate=5000,\n",
    "        extra_args=[\n",
    "            \"-pix_fmt\", \"yuv420p\",\n",
    "            \"-profile:v\", \"baseline\",\n",
    "            \"-level\", \"3.0\",\n",
    "            \"-movflags\", \"+faststart\"\n",
    "        ]\n",
    "    )\n",
    "    anim.save(out_mp4, writer=writer)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {out_mp4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7ec95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1/302 (0.3%) | elapsed 0.0m | ETA 0.0m\n",
      "Frame 6/302 (2.0%) | elapsed 0.1m | ETA 2.7m\n",
      "Frame 11/302 (3.6%) | elapsed 0.1m | ETA 2.5m\n",
      "Frame 16/302 (5.3%) | elapsed 0.1m | ETA 2.4m\n",
      "Frame 21/302 (7.0%) | elapsed 0.2m | ETA 2.5m\n",
      "Frame 26/302 (8.6%) | elapsed 0.2m | ETA 2.4m\n",
      "Frame 31/302 (10.3%) | elapsed 0.3m | ETA 2.5m\n",
      "Frame 36/302 (11.9%) | elapsed 0.3m | ETA 2.4m\n",
      "Frame 41/302 (13.6%) | elapsed 0.4m | ETA 2.3m\n",
      "Frame 46/302 (15.2%) | elapsed 0.4m | ETA 2.3m\n",
      "Frame 51/302 (16.9%) | elapsed 0.5m | ETA 2.2m\n",
      "Frame 56/302 (18.5%) | elapsed 0.5m | ETA 2.2m\n",
      "Frame 61/302 (20.2%) | elapsed 0.5m | ETA 2.2m\n",
      "Frame 66/302 (21.9%) | elapsed 0.6m | ETA 2.1m\n",
      "Frame 71/302 (23.5%) | elapsed 0.6m | ETA 2.1m\n",
      "Frame 76/302 (25.2%) | elapsed 0.7m | ETA 2.0m\n",
      "Frame 81/302 (26.8%) | elapsed 0.7m | ETA 2.0m\n",
      "Frame 86/302 (28.5%) | elapsed 0.8m | ETA 1.9m\n",
      "Frame 91/302 (30.1%) | elapsed 0.8m | ETA 1.9m\n",
      "Frame 96/302 (31.8%) | elapsed 0.9m | ETA 1.9m\n",
      "Frame 101/302 (33.4%) | elapsed 0.9m | ETA 1.8m\n",
      "Frame 106/302 (35.1%) | elapsed 1.0m | ETA 1.8m\n",
      "Frame 111/302 (36.8%) | elapsed 1.0m | ETA 1.7m\n",
      "Frame 116/302 (38.4%) | elapsed 1.1m | ETA 1.7m\n",
      "Frame 121/302 (40.1%) | elapsed 1.1m | ETA 1.6m\n",
      "Frame 126/302 (41.7%) | elapsed 1.1m | ETA 1.6m\n",
      "Frame 131/302 (43.4%) | elapsed 1.2m | ETA 1.6m\n",
      "Frame 136/302 (45.0%) | elapsed 1.2m | ETA 1.5m\n",
      "Frame 141/302 (46.7%) | elapsed 1.3m | ETA 1.5m\n",
      "Frame 146/302 (48.3%) | elapsed 1.3m | ETA 1.4m\n",
      "Frame 151/302 (50.0%) | elapsed 1.4m | ETA 1.4m\n",
      "Frame 156/302 (51.7%) | elapsed 1.4m | ETA 1.3m\n",
      "Frame 161/302 (53.3%) | elapsed 1.5m | ETA 1.3m\n",
      "Frame 166/302 (55.0%) | elapsed 1.5m | ETA 1.2m\n",
      "Frame 171/302 (56.6%) | elapsed 1.5m | ETA 1.2m\n",
      "Frame 176/302 (58.3%) | elapsed 1.6m | ETA 1.1m\n",
      "Frame 181/302 (59.9%) | elapsed 1.6m | ETA 1.1m\n",
      "Frame 186/302 (61.6%) | elapsed 1.7m | ETA 1.0m\n",
      "Frame 191/302 (63.2%) | elapsed 1.7m | ETA 1.0m\n",
      "Frame 196/302 (64.9%) | elapsed 1.8m | ETA 1.0m\n",
      "Frame 201/302 (66.6%) | elapsed 1.8m | ETA 0.9m\n",
      "Frame 206/302 (68.2%) | elapsed 1.8m | ETA 0.9m\n",
      "Frame 211/302 (69.9%) | elapsed 1.9m | ETA 0.8m\n",
      "Frame 216/302 (71.5%) | elapsed 1.9m | ETA 0.8m\n",
      "Frame 221/302 (73.2%) | elapsed 2.0m | ETA 0.7m\n",
      "Frame 226/302 (74.8%) | elapsed 2.0m | ETA 0.7m\n",
      "Frame 231/302 (76.5%) | elapsed 2.1m | ETA 0.6m\n",
      "Frame 236/302 (78.1%) | elapsed 2.1m | ETA 0.6m\n",
      "Frame 241/302 (79.8%) | elapsed 2.1m | ETA 0.5m\n",
      "Frame 246/302 (81.5%) | elapsed 2.2m | ETA 0.5m\n",
      "Frame 251/302 (83.1%) | elapsed 2.2m | ETA 0.5m\n",
      "Frame 256/302 (84.8%) | elapsed 2.3m | ETA 0.4m\n",
      "Frame 261/302 (86.4%) | elapsed 2.3m | ETA 0.4m\n",
      "Frame 266/302 (88.1%) | elapsed 2.4m | ETA 0.3m\n",
      "Frame 271/302 (89.7%) | elapsed 2.4m | ETA 0.3m\n",
      "Frame 276/302 (91.4%) | elapsed 2.5m | ETA 0.2m\n",
      "Frame 281/302 (93.0%) | elapsed 2.5m | ETA 0.2m\n",
      "Frame 286/302 (94.7%) | elapsed 2.5m | ETA 0.1m\n",
      "Frame 291/302 (96.4%) | elapsed 2.6m | ETA 0.1m\n",
      "Frame 296/302 (98.0%) | elapsed 2.6m | ETA 0.1m\n",
      "Frame 301/302 (99.7%) | elapsed 2.7m | ETA 0.0m\n",
      "Frame 302/302 (100.0%) | elapsed 2.7m | ETA 0.0m\n",
      "Saved: featuresqaemb/videos/karaoke_UTS01_wheretheressmoke.mp4\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "if plt is None:\n",
    "    raise RuntimeError('Matplotlib unavailable in this environment.')\n",
    "\n",
    "if shutil.which('ffmpeg') is None:\n",
    "    raise RuntimeError('ffmpeg not found on PATH. Install ffmpeg to write MP4 files.')\n",
    "\n",
    "make_karaoke_category_video(\n",
    "    result=result,\n",
    "    token_df=TOKEN_BASE_DF,\n",
    "    category_cols=category_cols_12,\n",
    "    out_mp4=KARAOKE_OUTPUT,\n",
    "    use_domain=KARAOKE_USE_DOMAIN,\n",
    "    fps=KARAOKE_FPS,\n",
    "    window_sec=KARAOKE_WINDOW_SEC,\n",
    "    pad_left_sec=KARAOKE_PAD_LEFT_SEC,\n",
    "    pad_right_sec=KARAOKE_PAD_RIGHT_SEC,\n",
    "        log_every_frames=KARAOKE_LOG_EVERY_FRAMES,\n",
    "    playback_speed=KARAOKE_PLAYBACK_SPEED,\n",
    "    ypad_frac=KARAOKE_YLIM_PAD_FRAC,\n",
    "    bin_words_max=KARAOKE_BIN_WORDS_MAX,\n",
    "    zscore=KARAOKE_ZSCORE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fead7345",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- If you want different categories, set `KARAOKE_CATEGORY_COLUMNS` to an explicit list of 12.\n",
    "- For faster preview, reduce `KARAOKE_FPS` or `KARAOKE_WINDOW_SEC`.\n",
    "- The output MP4 path is set by `KARAOKE_OUTPUT`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
